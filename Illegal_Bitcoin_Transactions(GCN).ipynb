{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC0Tr7IVUPzSZTN1FrP1rK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/graph-tutorial/blob/master/Illegal_Bitcoin_Transactions(GCN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Tb9O0cyBnk",
        "outputId": "86dcd04c-3bca-433a-c2a0-d1c91a456259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "elliptic-data-set.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  elliptic-data-set.zip\n",
            "replace elliptic_bitcoin_dataset/elliptic_txs_classes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# Install Kaggle API.\n",
        "!pip install kaggle\n",
        "# Run the following code to configure the path to “kaggle.json”\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!kaggle datasets download -d ellipticco/elliptic-data-set\n",
        "!unzip elliptic-data-set.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMP6iHodsAKe",
        "outputId": "f5b2a04e-e8ab-4999-f45a-017b337530a8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'axes.facecolor':'dimgrey', 'grid.color':'lightgrey'})\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#import torch_scatter\n",
        "from torch_geometric.data import Data\n",
        "print(torch.__version__)\n",
        "\n",
        "# # The PyG built-in GCNConv\n",
        "# from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax, degree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,roc_auc_score\n",
        "import scipy.sparse as scsp\n",
        "from sklearn.cluster import KMeans\n",
        "import copy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12QAVJzYr7lV",
        "outputId": "f7b1075f-d7db-4999-c524-64dc78d2deb4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content'\n",
        "\n",
        "edges = pd.read_csv(path + \"/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
        "classes = pd.read_csv(path + \"/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(path + \"/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header=None)"
      ],
      "metadata": {
        "id": "2TRgKzYArum0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "WbfsfMMRtAgk",
        "outputId": "fc4784ee-8c6a-4195-eb62-45d3bbead9b5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0  1         2         3         4        5         6         7  \\\n",
              "0  230425980  1 -0.171469 -0.184668 -1.201369 -0.12197 -0.043875 -0.113002   \n",
              "1    5530458  1 -0.171484 -0.184668 -1.201369 -0.12197 -0.043875 -0.113002   \n",
              "\n",
              "          8         9  \n",
              "0 -0.061584 -0.162097  \n",
              "1 -0.061584 -0.162112  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e68b5be9-3eb8-4002-8514-2da7c6fe169e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171469</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.12197</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171484</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.12197</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e68b5be9-3eb8-4002-8514-2da7c6fe169e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e68b5be9-3eb8-4002-8514-2da7c6fe169e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e68b5be9-3eb8-4002-8514-2da7c6fe169e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "dw7nyJ-ktHft",
        "outputId": "b1bfa6db-159b-4714-8679-737c30fc5657"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId    class\n",
              "0  230425980  unknown\n",
              "1    5530458  unknown"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5652fe2-f868-47ab-923d-4c276cb955fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5652fe2-f868-47ab-923d-4c276cb955fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5652fe2-f868-47ab-923d-4c276cb955fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5652fe2-f868-47ab-923d-4c276cb955fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XwRFuydws3Y2",
        "outputId": "17293fcd-5dbc-410f-f06c-afb53c4d9217"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       txId1      txId2\n",
              "0  230425980    5530458\n",
              "1  232022460  232438397\n",
              "2  230460314  230459870\n",
              "3  230333930  230595899\n",
              "4  232013274  232029206"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3769c7c8-f2ed-488a-8b7c-9152394b980e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId1</th>\n",
              "      <th>txId2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>5530458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>232022460</td>\n",
              "      <td>232438397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>230460314</td>\n",
              "      <td>230459870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230333930</td>\n",
              "      <td>230595899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>232013274</td>\n",
              "      <td>232029206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3769c7c8-f2ed-488a-8b7c-9152394b980e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3769c7c8-f2ed-488a-8b7c-9152394b980e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3769c7c8-f2ed-488a-8b7c-9152394b980e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename features\n",
        "rename_dict = dict(\n",
        "    zip(\n",
        "        range(0, 167),\n",
        "        [\"txId\", \"time_step\"]\n",
        "        + [i for i in range(2, 168)]\n",
        "    )\n",
        ")\n",
        "features.rename(columns=rename_dict, inplace=True)"
      ],
      "metadata": {
        "id": "tpTbpUDyvRIT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "iv9GfFwOvu5u",
        "outputId": "c78092f0-6ce6-4cc2-ba9a-0dc1889dac11"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId  time_step         2         3         4          5         6  \\\n",
              "0  230425980          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "1    5530458          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "2  232022460          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "3  232438397          1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
              "4  230460314          1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
              "\n",
              "          7          8         9  ...       157       158       159       160  \\\n",
              "0 -0.113002  -0.061584 -0.162097  ... -0.562153 -0.600999  1.461330  1.461369   \n",
              "1 -0.113002  -0.061584 -0.162112  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
              "2 -0.113002  -0.061584 -0.162749  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
              "3  9.782742  12.414558 -0.163645  ... -0.577099 -0.613614  0.241128  0.241406   \n",
              "4  1.312656  -0.061584 -0.163523  ... -0.511871 -0.400422  0.517257  0.579382   \n",
              "\n",
              "        161       162       163       164       165       166  \n",
              "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
              "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
              "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
              "\n",
              "[5 rows x 167 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d930345-0dac-4c1d-a853-eb7866b5cc74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>time_step</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171469</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162097</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.562153</td>\n",
              "      <td>-0.600999</td>\n",
              "      <td>1.461330</td>\n",
              "      <td>1.461369</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171484</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162112</td>\n",
              "      <td>...</td>\n",
              "      <td>0.947382</td>\n",
              "      <td>0.673103</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232022460</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172107</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162749</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670883</td>\n",
              "      <td>0.439728</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>-0.098889</td>\n",
              "      <td>-0.106715</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.183671</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>232438397</td>\n",
              "      <td>1</td>\n",
              "      <td>0.163054</td>\n",
              "      <td>1.963790</td>\n",
              "      <td>-0.646376</td>\n",
              "      <td>12.409294</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>9.782742</td>\n",
              "      <td>12.414558</td>\n",
              "      <td>-0.163645</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>0.085530</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>0.677799</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230460314</td>\n",
              "      <td>1</td>\n",
              "      <td>1.011523</td>\n",
              "      <td>-0.081127</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>1.153668</td>\n",
              "      <td>0.333276</td>\n",
              "      <td>1.312656</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.163523</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.511871</td>\n",
              "      <td>-0.400422</td>\n",
              "      <td>0.517257</td>\n",
              "      <td>0.579382</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>0.277775</td>\n",
              "      <td>0.326394</td>\n",
              "      <td>1.293750</td>\n",
              "      <td>0.178136</td>\n",
              "      <td>0.179117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 167 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d930345-0dac-4c1d-a853-eb7866b5cc74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d930345-0dac-4c1d-a853-eb7866b5cc74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d930345-0dac-4c1d-a853-eb7866b5cc74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the classes to ints that can be handled by pytorch as labels\n",
        "classes[\"class\"] = classes[\"class\"].replace(\n",
        "    {\"unknown\": -1,  # unlabeled nodes\n",
        "     \"2\": 0,  # labeled licit nodes\n",
        "     #\"1\": 1,  # labeled illicit nodes\n",
        "    }\n",
        ").astype(int)"
      ],
      "metadata": {
        "id": "VxdjUZQnwRqf"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge features and labels\n",
        "df = features.merge(classes, how=\"left\", left_on=\"txId\", right_on=\"txId\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "z1OO75zMwTcA",
        "outputId": "3501242b-08df-4f49-a01c-879df484c1e3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId  time_step         2         3         4          5         6  \\\n",
              "0  230425980          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "1    5530458          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "2  232022460          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875   \n",
              "3  232438397          1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n",
              "4  230460314          1  1.011523 -0.081127 -1.201369   1.153668  0.333276   \n",
              "\n",
              "          7          8         9  ...       158       159       160       161  \\\n",
              "0 -0.113002  -0.061584 -0.162097  ... -0.600999  1.461330  1.461369  0.018279   \n",
              "1 -0.113002  -0.061584 -0.162112  ...  0.673103 -0.979074 -0.978556  0.018279   \n",
              "2 -0.113002  -0.061584 -0.162749  ...  0.439728 -0.979074 -0.978556 -0.098889   \n",
              "3  9.782742  12.414558 -0.163645  ... -0.613614  0.241128  0.241406  1.072793   \n",
              "4  1.312656  -0.061584 -0.163523  ... -0.400422  0.517257  0.579382  0.018279   \n",
              "\n",
              "        162       163       164       165       166  class  \n",
              "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792     -1  \n",
              "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792     -1  \n",
              "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792     -1  \n",
              "3  0.085530 -0.131155  0.677799 -0.120613 -0.119792      0  \n",
              "4  0.277775  0.326394  1.293750  0.178136  0.179117     -1  \n",
              "\n",
              "[5 rows x 168 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b056d03-fce9-40ba-bb0a-774dc1d4f4c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>time_step</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171469</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162097</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.600999</td>\n",
              "      <td>1.461330</td>\n",
              "      <td>1.461369</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171484</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162112</td>\n",
              "      <td>...</td>\n",
              "      <td>0.673103</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232022460</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172107</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162749</td>\n",
              "      <td>...</td>\n",
              "      <td>0.439728</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>-0.098889</td>\n",
              "      <td>-0.106715</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.183671</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>232438397</td>\n",
              "      <td>1</td>\n",
              "      <td>0.163054</td>\n",
              "      <td>1.963790</td>\n",
              "      <td>-0.646376</td>\n",
              "      <td>12.409294</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>9.782742</td>\n",
              "      <td>12.414558</td>\n",
              "      <td>-0.163645</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>0.085530</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>0.677799</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230460314</td>\n",
              "      <td>1</td>\n",
              "      <td>1.011523</td>\n",
              "      <td>-0.081127</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>1.153668</td>\n",
              "      <td>0.333276</td>\n",
              "      <td>1.312656</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.163523</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.400422</td>\n",
              "      <td>0.517257</td>\n",
              "      <td>0.579382</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>0.277775</td>\n",
              "      <td>0.326394</td>\n",
              "      <td>1.293750</td>\n",
              "      <td>0.178136</td>\n",
              "      <td>0.179117</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 168 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b056d03-fce9-40ba-bb0a-774dc1d4f4c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b056d03-fce9-40ba-bb0a-774dc1d4f4c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b056d03-fce9-40ba-bb0a-774dc1d4f4c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_column = df.pop('class')\n"
      ],
      "metadata": {
        "id": "ThRQcMRZxR_Y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.insert(1, 'class', class_column)"
      ],
      "metadata": {
        "id": "Y_tMoLQWydku"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "wdfHkfm3yny_",
        "outputId": "2a926c93-f2af-45bf-a204-698c4a89dffe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId  class  time_step         2         3         4          5  \\\n",
              "0  230425980     -1          1 -0.171469 -0.184668 -1.201369  -0.121970   \n",
              "1    5530458     -1          1 -0.171484 -0.184668 -1.201369  -0.121970   \n",
              "2  232022460     -1          1 -0.172107 -0.184668 -1.201369  -0.121970   \n",
              "3  232438397      0          1  0.163054  1.963790 -0.646376  12.409294   \n",
              "4  230460314     -1          1  1.011523 -0.081127 -1.201369   1.153668   \n",
              "\n",
              "          6         7          8  ...       157       158       159       160  \\\n",
              "0 -0.043875 -0.113002  -0.061584  ... -0.562153 -0.600999  1.461330  1.461369   \n",
              "1 -0.043875 -0.113002  -0.061584  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
              "2 -0.043875 -0.113002  -0.061584  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
              "3 -0.063725  9.782742  12.414558  ... -0.577099 -0.613614  0.241128  0.241406   \n",
              "4  0.333276  1.312656  -0.061584  ... -0.511871 -0.400422  0.517257  0.579382   \n",
              "\n",
              "        161       162       163       164       165       166  \n",
              "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
              "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
              "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
              "\n",
              "[5 rows x 168 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1b1c76a-4503-4b73-9c07-d138fbda2e8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "      <th>time_step</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171469</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.562153</td>\n",
              "      <td>-0.600999</td>\n",
              "      <td>1.461330</td>\n",
              "      <td>1.461369</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171484</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.947382</td>\n",
              "      <td>0.673103</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232022460</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172107</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670883</td>\n",
              "      <td>0.439728</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>-0.098889</td>\n",
              "      <td>-0.106715</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.183671</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>232438397</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.163054</td>\n",
              "      <td>1.963790</td>\n",
              "      <td>-0.646376</td>\n",
              "      <td>12.409294</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>9.782742</td>\n",
              "      <td>12.414558</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>0.085530</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>0.677799</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230460314</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.011523</td>\n",
              "      <td>-0.081127</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>1.153668</td>\n",
              "      <td>0.333276</td>\n",
              "      <td>1.312656</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.511871</td>\n",
              "      <td>-0.400422</td>\n",
              "      <td>0.517257</td>\n",
              "      <td>0.579382</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>0.277775</td>\n",
              "      <td>0.326394</td>\n",
              "      <td>1.293750</td>\n",
              "      <td>0.178136</td>\n",
              "      <td>0.179117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 168 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1b1c76a-4503-4b73-9c07-d138fbda2e8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1b1c76a-4503-4b73-9c07-d138fbda2e8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1b1c76a-4503-4b73-9c07-d138fbda2e8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame and reset index\n",
        "#df.sort_values(\"txId\", inplace=True)\n",
        "#df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Check the length of df and classes\n",
        "if len(df) != len(classes):\n",
        "    print(\"Error: Lengths of df and classes do not match.\")\n",
        "\n",
        "# Drop unclassified and isolated nodes\n",
        "classified_nodes = set(classes[classes[\"class\"] != -1][\"txId\"].values)\n",
        "classified_edges = edges[(edges[\"txId1\"].isin(classified_nodes)) & (edges[\"txId2\"].isin(classified_nodes))].copy()\n",
        "non_isolated_nodes = set(classified_edges[\"txId1\"].values).union(classified_edges[\"txId2\"].values)\n",
        "classified_df = df[df[\"txId\"].isin(non_isolated_nodes)].copy()\n"
      ],
      "metadata": {
        "id": "aZdG0AFky2cJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classified_df.reset_index(drop=True, inplace=True)\n",
        "classified_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "89NjmUEizQM6",
        "outputId": "375ad589-d08e-4acf-cf22-cfba67051302"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId  class  time_step         2         3         4          5  \\\n",
              "0  232438397      0          1  0.163054  1.963790 -0.646376  12.409294   \n",
              "1  232029206      0          1 -0.005027  0.578941 -0.091383   4.380281   \n",
              "2  232344069      0          1 -0.147852 -0.184668 -1.201369  -0.121970   \n",
              "3   27553029      0          1 -0.151357 -0.184668 -1.201369  -0.121970   \n",
              "4    3881097      0          1 -0.172306 -0.184668 -1.201369   0.028105   \n",
              "\n",
              "          6         7          8  ...       157       158       159       160  \\\n",
              "0 -0.063725  9.782742  12.414558  ... -0.577099 -0.613614  0.241128  0.241406   \n",
              "1 -0.063725  4.667146   0.851305  ... -0.577099 -0.613614  0.241128  0.241406   \n",
              "2 -0.043875 -0.113002  -0.061584  ... -0.577099 -0.613614  0.241128  0.241406   \n",
              "3 -0.043875 -0.113002  -0.061584  ... -0.539735 -0.582077 -0.979074 -0.978556   \n",
              "4 -0.043875 -0.029140   0.242712  ... -0.577099 -0.600999  0.241128  0.241406   \n",
              "\n",
              "        161       162       163       164       165       166  \n",
              "0  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
              "1  0.604120  0.008632 -0.131155  0.333211 -0.120613 -0.119792  \n",
              "2  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "3  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "4  0.018279 -0.068266 -0.084674 -0.054450 -1.760926 -1.760984  \n",
              "\n",
              "[5 rows x 168 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-165080d6-880b-4ee4-af51-03918c0f1bc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "      <th>time_step</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>232438397</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.163054</td>\n",
              "      <td>1.963790</td>\n",
              "      <td>-0.646376</td>\n",
              "      <td>12.409294</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>9.782742</td>\n",
              "      <td>12.414558</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>1.072793</td>\n",
              "      <td>0.085530</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>0.677799</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>232029206</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.005027</td>\n",
              "      <td>0.578941</td>\n",
              "      <td>-0.091383</td>\n",
              "      <td>4.380281</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>4.667146</td>\n",
              "      <td>0.851305</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>0.604120</td>\n",
              "      <td>0.008632</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>0.333211</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232344069</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.147852</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27553029</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.151357</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.121970</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.539735</td>\n",
              "      <td>-0.582077</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3881097</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172306</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>0.028105</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.029140</td>\n",
              "      <td>0.242712</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577099</td>\n",
              "      <td>-0.600999</td>\n",
              "      <td>0.241128</td>\n",
              "      <td>0.241406</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.068266</td>\n",
              "      <td>-0.084674</td>\n",
              "      <td>-0.054450</td>\n",
              "      <td>-1.760926</td>\n",
              "      <td>-1.760984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 168 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-165080d6-880b-4ee4-af51-03918c0f1bc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-165080d6-880b-4ee4-af51-03918c0f1bc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-165080d6-880b-4ee4-af51-03918c0f1bc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classified_df.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8uiRmTo1968",
        "outputId": "385a03db-9059-42d5-c8b6-8ad5269e9fc1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of             txId  class  time_step         2         3         4          5  \\\n",
              "0      232438397      0          1  0.163054  1.963790 -0.646376  12.409294   \n",
              "1      232029206      0          1 -0.005027  0.578941 -0.091383   4.380281   \n",
              "2      232344069      0          1 -0.147852 -0.184668 -1.201369  -0.121970   \n",
              "3       27553029      0          1 -0.151357 -0.184668 -1.201369  -0.121970   \n",
              "4        3881097      0          1 -0.172306 -0.184668 -1.201369   0.028105   \n",
              "...          ...    ...        ...       ...       ...       ...        ...   \n",
              "35869   80329479      0         49 -0.159293 -0.037276  1.018602  -0.121970   \n",
              "35870  158406298      0         49 -0.172962 -0.126566  1.018602  -0.121970   \n",
              "35871  158375075      1         49 -0.170412 -0.078164  1.018602   0.028105   \n",
              "35872  147478192      0         49 -0.093732 -0.116160  1.018602  -0.121970   \n",
              "35873  158375402      1         49 -0.172014 -0.078182  1.018602   0.028105   \n",
              "\n",
              "              6         7          8  ...       157       158       159  \\\n",
              "0     -0.063725  9.782742  12.414558  ... -0.577099 -0.613614  0.241128   \n",
              "1     -0.063725  4.667146   0.851305  ... -0.577099 -0.613614  0.241128   \n",
              "2     -0.043875 -0.113002  -0.061584  ... -0.577099 -0.613614  0.241128   \n",
              "3     -0.043875 -0.113002  -0.061584  ... -0.539735 -0.582077 -0.979074   \n",
              "4     -0.043875 -0.029140   0.242712  ... -0.577099 -0.600999  0.241128   \n",
              "...         ...       ...        ...  ...       ...       ...       ...   \n",
              "35869  0.035526 -0.113002  -0.061584  ...  1.793987  1.408971  0.231244   \n",
              "35870 -0.063725 -0.113002  -0.061584  ... -0.577099  0.647874  0.241128   \n",
              "35871 -0.043875  0.054722  -0.061584  ...  1.709623  1.606604  1.461330   \n",
              "35872 -0.043875 -0.113002  -0.061584  ... -0.577099 -0.613614  0.241128   \n",
              "35873 -0.043875  0.054722  -0.061584  ...  1.261246  1.985050  1.461330   \n",
              "\n",
              "            160        161       162       163       164       165       166  \n",
              "0      0.241406   1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
              "1      0.241406   0.604120  0.008632 -0.131155  0.333211 -0.120613 -0.119792  \n",
              "2      0.241406   0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "3     -0.978556   0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "4      0.241406   0.018279 -0.068266 -0.084674 -0.054450 -1.760926 -1.760984  \n",
              "...         ...        ...       ...       ...       ...       ...       ...  \n",
              "35869 -0.388216  -0.098889  1.931078  3.168259  3.707301 -1.390548 -1.214035  \n",
              "35870  0.241406  10.914916  1.700384 -0.131155  7.914145 -0.120613 -0.119792  \n",
              "35871  1.461369   0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "35872  0.241406   0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "35873  1.461369   0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
              "\n",
              "[35874 rows x 168 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classified_edges.reset_index(drop=True, inplace=True)\n",
        "classified_edges.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ySV7EwFI0CE4",
        "outputId": "329b1ea8-7428-4e37-f939-09514a05070a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       txId1      txId2\n",
              "0  232344069   27553029\n",
              "1    3881097  232457116\n",
              "2  232051089  232470704\n",
              "3  230473487    7089694\n",
              "4  231182296   14660781"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb4f2ae2-60c0-4198-9bad-09939e77a365\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId1</th>\n",
              "      <th>txId2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>232344069</td>\n",
              "      <td>27553029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3881097</td>\n",
              "      <td>232457116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232051089</td>\n",
              "      <td>232470704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230473487</td>\n",
              "      <td>7089694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>231182296</td>\n",
              "      <td>14660781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb4f2ae2-60c0-4198-9bad-09939e77a365')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb4f2ae2-60c0-4198-9bad-09939e77a365 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb4f2ae2-60c0-4198-9bad-09939e77a365');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classified_edges.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvDDoYSq1zcT",
        "outputId": "045fa705-4152-4988-e9d9-9b8a656604d3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of            txId1      txId2\n",
              "0      232344069   27553029\n",
              "1        3881097  232457116\n",
              "2      232051089  232470704\n",
              "3      230473487    7089694\n",
              "4      231182296   14660781\n",
              "...          ...        ...\n",
              "36619  194020062   47521535\n",
              "36620  158574502  109383451\n",
              "36621  158594124  157631640\n",
              "36622  157631640   21644119\n",
              "36623  158365409  157930723\n",
              "\n",
              "[36624 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classified_edges.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcc26zMs7La9",
        "outputId": "0929adbc-33d7-45cf-997c-f0fa7acf7a84"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[232344069,  27553029],\n",
              "       [  3881097, 232457116],\n",
              "       [232051089, 232470704],\n",
              "       ...,\n",
              "       [158594124, 157631640],\n",
              "       [157631640,  21644119],\n",
              "       [158365409, 157930723]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features =  torch.FloatTensor(classified_df.iloc[:, 2:].to_numpy())\n",
        "labels = classified_df.iloc[:, 1].to_numpy()\n",
        "labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "nodes_id = classified_df.iloc[:, 0].to_numpy()"
      ],
      "metadata": {
        "id": "maZTunL-2k-d"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpLkPNCu4E-l",
        "outputId": "64fd3151-a549-468e-9e97-4cb18f95fd97"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([35874, 166])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# train_size = 0.6\n",
        "# test_size = 0.3\n",
        "# val_size = 0.1"
      ],
      "metadata": {
        "id": "R2QmPGyp4M-d"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary that maps nodeId to index in the dataframe.\n",
        "id2idx = {}\n",
        "for i in range(classified_df.shape[0]):\n",
        "    id2idx[classified_df.iloc[i, 0]] = i\n",
        "\n",
        "# Construct edge_index with same node indexing as in features and labels\n",
        "edge_idx = np.zeros((2, classified_edges.shape[0]), dtype = np.int64)\n",
        "for index in range(classified_edges.shape[0]):\n",
        "    node1 = id2idx[classified_edges.iloc[index, 0]]\n",
        "    node2 = id2idx[classified_edges.iloc[index, 1]]\n",
        "    edge_idx[:, index] = [node1, node2]\n",
        "edge_index = torch.LongTensor(edge_idx)\n",
        "\n",
        "train_index, test_index = train_test_split(np.arange(labels.shape[0]),\n",
        "                                            test_size = 0.4,\n",
        "                                            random_state = 42)\n",
        "val_index, test_index = train_test_split(test_index,\n",
        "                                          test_size = 0.75,\n",
        "                                          random_state = 42)\n",
        "\n",
        "# Construct the training, validation, test set and store in a dictionary, 'data'.\n",
        "data = Data(x = features, edge_index = edge_index, y = labels).to(device)\n",
        ""
      ],
      "metadata": {
        "id": "TmjHCzml3-yA"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = {'train': train_index, 'val': val_index, 'test': test_index}"
      ],
      "metadata": {
        "id": "aehf-Ve2BtyX"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_size = ',train_index.shape[0]/labels.shape[0])\n",
        "print('test_size = ',test_index.shape[0]/labels.shape[0])\n",
        "print('val_size = ',val_index.shape[0]/labels.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eHRXQlT-OPx",
        "outputId": "022bbdd4-01bd-4434-b499-6e6e8be0d108"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size =  0.5999888498634108\n",
            "test_size =  0.30002230027317833\n",
            "val_size =  0.09998884986341083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds = False):\n",
        "        \"\"\"\n",
        "        Initialize a GCN model.\n",
        "        Args:\n",
        "            input_dim       Input dimension of node embeddings\n",
        "            hidden_dim      Hidden dimension of node embeddings\n",
        "            output_dim      Output dimension of node embeddings\n",
        "            num_layers      The number of GCN layers\n",
        "            dropout         The dropout ratio in (0, 1]\n",
        "                              (dropout: the probability of an element getting zeroed)\n",
        "            return_embeds   A boolean value determining whether we skip the\n",
        "                              classification layer and return node embeddings\n",
        "        \"\"\"\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # Construct all convs\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = torch.nn.ModuleList([GCNLayer(hidden_dim, hidden_dim, directed = False)\n",
        "                                                        for i in range(self.num_layers-1)])\n",
        "\n",
        "        # Construct batch normalization\n",
        "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim)\n",
        "                                        for i in range(self.num_layers-1)])\n",
        "        # First GCN layer\n",
        "        self.convs[0] = GCNLayer(input_dim, hidden_dim, directed = False)\n",
        "        # Last GCN layer\n",
        "        self.last_conv = GCNLayer(hidden_dim, output_dim, directed = False)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim = -1)\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Reset all learnable parameters in GCN layers and Batch Normalization\n",
        "        Layers.\n",
        "        \"\"\"\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Produce a forward propagation of GCN model. Before the last GCN layer,\n",
        "        we transform the embedding (x) in the following sequence:\n",
        "          x -> GCN_Layer -> Batch_Norm -> ReLU -> Dropout.\n",
        "        At the last GCN layer, the following sequence is applied:\n",
        "          x -> GCN Layer -> Softmax -> output.\n",
        "\n",
        "        Args:\n",
        "            x             The node embedding\n",
        "            edge_index    The adjacency list of the graph\n",
        "\n",
        "        Returns:\n",
        "            out           The predictions of labels / the updated node embedding\n",
        "        \"\"\"\n",
        "        x = torch.clone(x.detach())\n",
        "        for l in range(self.num_layers - 1):\n",
        "            # Unweighted graph has weight 1.\n",
        "            x = self.convs[l](x, edge_index, torch.ones(edge_index.shape[1]))\n",
        "            x = self.bns[l](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p = self.dropout, training = self.training)\n",
        "\n",
        "        x = self.last_conv(x, edge_index, torch.ones(edge_index.shape[1]))\n",
        "        if self.return_embeds:\n",
        "            out = x\n",
        "        else:\n",
        "            out = self.softmax(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "9mIHBW8zAuOj"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, bias = True,\n",
        "                 directed = False, self_loop = True, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize a GCN layer.\n",
        "        Args:\n",
        "            in_channels      In-channel dimension of node embeddings\n",
        "            out_channels     Out-channel dimension of node embeddings\n",
        "            bias             A boolean value determining whether we add a\n",
        "                                learnable bias term in linear transformation\n",
        "            directed         A boolean value determining whether we use directed\n",
        "                                message passing D^{-1}A or use symmetric normalized\n",
        "                                adjacency matrix D^{-1/2}AD^{-1/2}\n",
        "            self_loop        A boolean value determining whether we add a self-\n",
        "                                loop for each node\n",
        "        \"\"\"\n",
        "        super(GCNLayer, self).__init__(**kwargs, aggr = 'add')\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.directed = directed\n",
        "        self.self_loop = self_loop\n",
        "\n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin is the linear transformation that we apply to the embedding.\n",
        "        self.lin = nn.Linear(self.in_channels, self.out_channels, bias = bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Reset all learnable parameters in the linear transformation.\n",
        "        \"\"\"\n",
        "        self.lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        \"\"\"\n",
        "        Produce a forward propagation of GCN layer.\n",
        "\n",
        "        Args:\n",
        "            x             The node embedding\n",
        "            edge_index    The (2, |E|) adjacency list of the graph\n",
        "            edge_weight   The (|E|) vector specifying the edge weights in the graph\n",
        "                            (for unweighted graph, edge weight is 1)\n",
        "\n",
        "        Returns:\n",
        "            An updated node embedding\n",
        "        \"\"\"\n",
        "        # Add self-loops to the adjacency matrix.\n",
        "        if self.self_loop:\n",
        "            edge_index, _ = add_self_loops(edge_index, num_nodes = x.size(0))\n",
        "            edge_weight = torch.cat((edge_weight, torch.ones(x.size(0))), dim = -1)\n",
        "\n",
        "        # Apply linear transformation on node features.\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Compute normalization by updated node degree.\n",
        "        if self.directed:\n",
        "            row , _ = edge_index\n",
        "            deg = degree(row, x.size(0), dtype = x.dtype) # only out-degree\n",
        "            deg_inv = deg.pow(-1)\n",
        "            deg_inv[deg_inv == float('inf')] = 0\n",
        "            norm = deg_inv[row]\n",
        "        else:\n",
        "            row, col = edge_index\n",
        "            deg = degree(col, x.size(0), dtype = x.dtype)\n",
        "            deg_inv_sqrt = deg.pow(-0.5)\n",
        "            deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "            norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        return self.propagate(edge_index, x = (x, x), norm = norm, edge_weight = edge_weight)\n",
        "\n",
        "    def message(self, x_j, edge_weight, norm):\n",
        "        \"\"\"\n",
        "        Send the message of the neighboring node (i.e., x_j) to the source node (i.e., x_i).\n",
        "\n",
        "        Args:\n",
        "            x_j           The embedding of the neighboring node of source node x_i\n",
        "            edge_weight   The edge weight of certain edge\n",
        "            norm          Normalization constant determined by self.directed\n",
        "\n",
        "        Returns:\n",
        "            A message sending from the neighboring node to the source node\n",
        "        \"\"\"\n",
        "        return norm.view(-1, 1) * x_j * edge_weight.view(-1, 1)"
      ],
      "metadata": {
        "id": "ZwEM7tBUAyPI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transd(model, data, train_idx, optimizer, loss_fn):\n",
        "    \"\"\"\n",
        "    Train the model by using the given optimizer and loss_fn.\n",
        "\n",
        "    Args:\n",
        "        model       The GCN model\n",
        "        data        The Data object that stores x, edge_index, and labels\n",
        "        train_idx   The node indices in the training set\n",
        "        optimizer   The optimizer\n",
        "        loss_fn     The loss function\n",
        "\n",
        "    Returns\n",
        "        The prediction loss by the given loss function\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_slice = model.forward(data.x, data.edge_index)[train_idx]\n",
        "    train_label = data.y[train_idx]\n",
        "    loss = loss_fn(train_slice, train_label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "vDTeGcz9AzFU"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_transd(model, data, split_idx, save_model_results=False):\n",
        "    \"\"\"\n",
        "    Test the model by using the given split_idx.\n",
        "\n",
        "    Args:\n",
        "        model                 The GCN model\n",
        "        data                  The Data object that stores x, edge_index, and labels\n",
        "        split_idx             A dictionary that stores node indices for three sets\n",
        "        save_model_results    A boolean determining whether we save the model results\n",
        "\n",
        "    Returns\n",
        "        The accuracy and auc-roc score of training, validation, and test set\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    # The output of model on all data\n",
        "    out = model.forward(data.x, data.edge_index)\n",
        "\n",
        "    train_index = split_idx['train']\n",
        "    val_index = split_idx['val']\n",
        "    test_index = split_idx['test']\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "    train_acc = classification_report(torch.unsqueeze(data.y[train_index], -1),\n",
        "                                      y_pred[train_index], zero_division=0)\n",
        "    valid_acc = classification_report(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index], zero_division=0)\n",
        "    valid_accuracy = classification_report(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index], output_dict=True,\n",
        "                                      zero_division=0)['accuracy']\n",
        "    test_acc = classification_report(torch.unsqueeze(data.y[test_index], -1),\n",
        "                                     y_pred[test_index], zero_division=0)\n",
        "    train_auc_roc = roc_auc_score(torch.unsqueeze(data.y[train_index], -1),\n",
        "                                      y_pred[train_index])\n",
        "    val_auc_roc = roc_auc_score(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index])\n",
        "    test_auc_roc = roc_auc_score(torch.unsqueeze(data.y[test_index], -1),\n",
        "                                      y_pred[test_index])\n",
        "\n",
        "    if save_model_results:\n",
        "        print (\"Saving Model Predictions\")\n",
        "\n",
        "        data = {}\n",
        "        data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        df = pd.DataFrame(data=data)\n",
        "        # Save locally as csv\n",
        "        df.to_csv('gcn_transd.csv', sep=',', index=False)\n",
        "\n",
        "    return train_acc, valid_acc, test_acc, \\\n",
        "           train_auc_roc, val_auc_roc, test_auc_roc"
      ],
      "metadata": {
        "id": "-H5zflhKBAtp"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 2,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 50,\n",
        "    'label_weight': torch.Tensor([0.5, 0.5])\n",
        "}\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uJRvt7qBDik",
        "outputId": "b8277838-5b3b-40a1-d1b8-6ed2a1a1d10a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'device': 'cpu',\n",
              " 'num_layers': 2,\n",
              " 'hidden_dim': 256,\n",
              " 'dropout': 0.5,\n",
              " 'lr': 0.01,\n",
              " 'epochs': 50,\n",
              " 'label_weight': tensor([0.5000, 0.5000])}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(data.x.shape[1], args['hidden_dim'],\n",
        "            2, args['num_layers'], args['dropout']).to(device)"
      ],
      "metadata": {
        "id": "3c29Rg5dBHh1"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.NLLLoss(weight=args['label_weight'])\n",
        "\n",
        "best_model = None\n",
        "best_valid_auc = 0\n",
        "best_result = None\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "    # train with random split\n",
        "    loss = train_transd(model, data, split_idx['train'], optimizer, loss_fn)\n",
        "    losses.append(loss)\n",
        "    result = test_transd(model, data, split_idx)\n",
        "    train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result\n",
        "    if val_auc > best_valid_auc:\n",
        "        best_valid_auc = val_auc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
        "\n",
        "    print('Epoch: {:02},'.format(epoch),\n",
        "          'Loss:{:.4f}'.format(loss),\n",
        "          'Train:\\n{}\\n'.format(train_acc),\n",
        "          'Train_auc_roc: {}'.format(train_auc),\n",
        "          '\\n\\n'\n",
        "          'Valid:\\n{}\\n'.format(val_acc),\n",
        "          'Val_auc_roc: {}'.format(val_auc),\n",
        "          '\\n\\n'\n",
        "          'Test:\\n{}\\n'.format(test_acc),\n",
        "          'Test_auc_roc: {}'.format(test_auc),\n",
        "          '\\n'\n",
        "          )\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXexf0K-BRW6",
        "outputId": "379b4db7-8015-4558-edbd-131cf0d9f691"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss:0.2554 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 02, Loss:0.2000 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 03, Loss:0.1812 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.4999750499001996 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.49994996497548283 \n",
            "\n",
            "Epoch: 04, Loss:0.1773 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 05, Loss:0.1722 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 06, Loss:0.1714 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 07, Loss:0.1684 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     20040\n",
            "           1       0.00      0.00      0.00      1484\n",
            "\n",
            "    accuracy                           0.93     21524\n",
            "   macro avg       0.47      0.50      0.48     21524\n",
            "weighted avg       0.87      0.93      0.90     21524\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.00      0.00      0.00       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.47      0.50      0.48      3587\n",
            "weighted avg       0.88      0.94      0.90      3587\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      9993\n",
            "           1       0.00      0.00      0.00       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.46      0.50      0.48     10763\n",
            "weighted avg       0.86      0.93      0.89     10763\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 08, Loss:0.1635 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     20040\n",
            "           1       0.98      0.08      0.16      1484\n",
            "\n",
            "    accuracy                           0.94     21524\n",
            "   macro avg       0.96      0.54      0.56     21524\n",
            "weighted avg       0.94      0.94      0.91     21524\n",
            "\n",
            " Train_auc_roc: 0.542377979889278 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       1.00      0.07      0.14       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.97      0.54      0.55      3587\n",
            "weighted avg       0.94      0.94      0.92      3587\n",
            "\n",
            " Val_auc_roc: 0.5369565217391304 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.97      9993\n",
            "           1       0.98      0.08      0.15       770\n",
            "\n",
            "    accuracy                           0.93     10763\n",
            "   macro avg       0.96      0.54      0.56     10763\n",
            "weighted avg       0.94      0.93      0.91     10763\n",
            "\n",
            " Test_auc_roc: 0.540209705235223 \n",
            "\n",
            "Epoch: 09, Loss:0.1602 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     20040\n",
            "           1       0.93      0.14      0.25      1484\n",
            "\n",
            "    accuracy                           0.94     21524\n",
            "   macro avg       0.93      0.57      0.61     21524\n",
            "weighted avg       0.94      0.94      0.92     21524\n",
            "\n",
            " Train_auc_roc: 0.5710044197319646 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      3357\n",
            "           1       0.90      0.11      0.20       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.92      0.56      0.59      3587\n",
            "weighted avg       0.94      0.94      0.92      3587\n",
            "\n",
            " Val_auc_roc: 0.5560749116058592 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      9993\n",
            "           1       0.91      0.13      0.23       770\n",
            "\n",
            "    accuracy                           0.94     10763\n",
            "   macro avg       0.92      0.57      0.60     10763\n",
            "weighted avg       0.94      0.94      0.91     10763\n",
            "\n",
            " Test_auc_roc: 0.5663827666379452 \n",
            "\n",
            "Epoch: 10, Loss:0.1565 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     20040\n",
            "           1       0.89      0.17      0.28      1484\n",
            "\n",
            "    accuracy                           0.94     21524\n",
            "   macro avg       0.91      0.58      0.63     21524\n",
            "weighted avg       0.94      0.94      0.92     21524\n",
            "\n",
            " Train_auc_roc: 0.583770329960026 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      3357\n",
            "           1       0.86      0.17      0.28       230\n",
            "\n",
            "    accuracy                           0.94      3587\n",
            "   macro avg       0.90      0.58      0.62      3587\n",
            "weighted avg       0.94      0.94      0.93      3587\n",
            "\n",
            " Val_auc_roc: 0.5817150406030229 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      9993\n",
            "           1       0.87      0.16      0.27       770\n",
            "\n",
            "    accuracy                           0.94     10763\n",
            "   macro avg       0.91      0.58      0.62     10763\n",
            "weighted avg       0.93      0.94      0.92     10763\n",
            "\n",
            " Test_auc_roc: 0.5789694994288209 \n",
            "\n",
            "Epoch: 11, Loss:0.1529 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     20040\n",
            "           1       0.87      0.20      0.32      1484\n",
            "\n",
            "    accuracy                           0.94     21524\n",
            "   macro avg       0.91      0.60      0.65     21524\n",
            "weighted avg       0.94      0.94      0.93     21524\n",
            "\n",
            " Train_auc_roc: 0.5982957266060871 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      3357\n",
            "           1       0.86      0.21      0.34       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.90      0.60      0.65      3587\n",
            "weighted avg       0.94      0.95      0.93      3587\n",
            "\n",
            " Val_auc_roc: 0.6031562860214218 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      9993\n",
            "           1       0.84      0.19      0.31       770\n",
            "\n",
            "    accuracy                           0.94     10763\n",
            "   macro avg       0.89      0.59      0.64     10763\n",
            "weighted avg       0.93      0.94      0.92     10763\n",
            "\n",
            " Test_auc_roc: 0.592105512820013 \n",
            "\n",
            "Epoch: 12, Loss:0.1502 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97     20040\n",
            "           1       0.83      0.25      0.38      1484\n",
            "\n",
            "    accuracy                           0.94     21524\n",
            "   macro avg       0.89      0.62      0.68     21524\n",
            "weighted avg       0.94      0.94      0.93     21524\n",
            "\n",
            " Train_auc_roc: 0.6218059837198917 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      3357\n",
            "           1       0.83      0.26      0.39       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.89      0.63      0.68      3587\n",
            "weighted avg       0.94      0.95      0.94      3587\n",
            "\n",
            " Val_auc_roc: 0.6264735594669154 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      9993\n",
            "           1       0.82      0.23      0.36       770\n",
            "\n",
            "    accuracy                           0.94     10763\n",
            "   macro avg       0.88      0.61      0.66     10763\n",
            "weighted avg       0.93      0.94      0.93     10763\n",
            "\n",
            " Test_auc_roc: 0.6129836989788956 \n",
            "\n",
            "Epoch: 13, Loss:0.1471 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     20040\n",
            "           1       0.79      0.33      0.46      1484\n",
            "\n",
            "    accuracy                           0.95     21524\n",
            "   macro avg       0.87      0.66      0.72     21524\n",
            "weighted avg       0.94      0.95      0.94     21524\n",
            "\n",
            " Train_auc_roc: 0.6614639992252692 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      3357\n",
            "           1       0.78      0.33      0.47       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.87      0.66      0.72      3587\n",
            "weighted avg       0.94      0.95      0.94      3587\n",
            "\n",
            " Val_auc_roc: 0.6641145691676057 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      9993\n",
            "           1       0.78      0.32      0.45       770\n",
            "\n",
            "    accuracy                           0.94     10763\n",
            "   macro avg       0.86      0.65      0.71     10763\n",
            "weighted avg       0.94      0.94      0.93     10763\n",
            "\n",
            " Test_auc_roc: 0.654939106725357 \n",
            "\n",
            "Epoch: 14, Loss:0.1444 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     20040\n",
            "           1       0.75      0.39      0.52      1484\n",
            "\n",
            "    accuracy                           0.95     21524\n",
            "   macro avg       0.86      0.69      0.75     21524\n",
            "weighted avg       0.94      0.95      0.94     21524\n",
            "\n",
            " Train_auc_roc: 0.6926738840378542 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      3357\n",
            "           1       0.73      0.39      0.51       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.85      0.69      0.74      3587\n",
            "weighted avg       0.94      0.95      0.94      3587\n",
            "\n",
            " Val_auc_roc: 0.6907370711427129 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      9993\n",
            "           1       0.74      0.38      0.50       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.85      0.68      0.74     10763\n",
            "weighted avg       0.94      0.95      0.94     10763\n",
            "\n",
            " Test_auc_roc: 0.6827088702351386 \n",
            "\n",
            "Epoch: 15, Loss:0.1424 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     20040\n",
            "           1       0.74      0.43      0.54      1484\n",
            "\n",
            "    accuracy                           0.95     21524\n",
            "   macro avg       0.85      0.71      0.76     21524\n",
            "weighted avg       0.94      0.95      0.94     21524\n",
            "\n",
            " Train_auc_roc: 0.708934018754943 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      3357\n",
            "           1       0.70      0.43      0.53       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.83      0.71      0.75      3587\n",
            "weighted avg       0.94      0.95      0.95      3587\n",
            "\n",
            " Val_auc_roc: 0.7067878929168124 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      9993\n",
            "           1       0.74      0.42      0.54       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.85      0.70      0.75     10763\n",
            "weighted avg       0.94      0.95      0.94     10763\n",
            "\n",
            " Test_auc_roc: 0.7047856876436882 \n",
            "\n",
            "Epoch: 16, Loss:0.1387 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     20040\n",
            "           1       0.75      0.46      0.57      1484\n",
            "\n",
            "    accuracy                           0.95     21524\n",
            "   macro avg       0.85      0.73      0.77     21524\n",
            "weighted avg       0.95      0.95      0.95     21524\n",
            "\n",
            " Train_auc_roc: 0.7263544339891645 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      3357\n",
            "           1       0.72      0.45      0.55       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.84      0.72      0.77      3587\n",
            "weighted avg       0.95      0.95      0.95      3587\n",
            "\n",
            " Val_auc_roc: 0.7199803136858738 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      9993\n",
            "           1       0.75      0.44      0.56       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.86      0.72      0.77     10763\n",
            "weighted avg       0.94      0.95      0.94     10763\n",
            "\n",
            " Test_auc_roc: 0.7165240343565172 \n",
            "\n",
            "Epoch: 17, Loss:0.1366 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     20040\n",
            "           1       0.75      0.54      0.63      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.86      0.76      0.80     21524\n",
            "weighted avg       0.95      0.96      0.95     21524\n",
            "\n",
            " Train_auc_roc: 0.7609832894857186 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      3357\n",
            "           1       0.72      0.51      0.60       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.84      0.75      0.79      3587\n",
            "weighted avg       0.95      0.96      0.95      3587\n",
            "\n",
            " Val_auc_roc: 0.7495214412454184 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      9993\n",
            "           1       0.74      0.50      0.60       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.85      0.74      0.79     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.7444939379643672 \n",
            "\n",
            "Epoch: 18, Loss:0.1348 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     20040\n",
            "           1       0.72      0.62      0.67      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.80      0.82     21524\n",
            "weighted avg       0.95      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8014526876166803 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      3357\n",
            "           1       0.70      0.61      0.65       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.84      0.80      0.81      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.7954112755954463 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      9993\n",
            "           1       0.72      0.59      0.65       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.84      0.79      0.81     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.7859990304901744 \n",
            "\n",
            "Epoch: 19, Loss:0.1318 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.69      0.68      0.69      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.83      0.83     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8283950965992543 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.67      0.63      0.65       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.81      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8068163862662056 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      9993\n",
            "           1       0.68      0.64      0.66       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.83      0.81      0.82     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8104197613654234 \n",
            "\n",
            "Epoch: 20, Loss:0.1290 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.71      0.68      0.69      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.83      0.83     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8281328179221072 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.68      0.65      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.83      0.81      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8136360104130241 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      9993\n",
            "           1       0.69      0.65      0.67       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.83      0.81      0.82     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8116194972844628 \n",
            "\n",
            "Epoch: 21, Loss:0.1279 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.73      0.67      0.70      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.83      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8275958863943272 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.70      0.65      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.84      0.82      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8165546359974616 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      9993\n",
            "           1       0.71      0.64      0.67       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.81      0.83     10763\n",
            "weighted avg       0.95      0.96      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8101729002509549 \n",
            "\n",
            "Epoch: 22, Loss:0.1261 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.71      0.69      0.70      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.83      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.833411277176106 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.69      0.67      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.83      0.82      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8221827200787453 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      9993\n",
            "           1       0.70      0.66      0.68       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.82      0.83     10763\n",
            "weighted avg       0.95      0.96      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8172646176999224 \n",
            "\n",
            "Epoch: 23, Loss:0.1236 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.68      0.71      0.70      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.84      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8431827719224624 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.65      0.69      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.83      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.830818147673259 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      9993\n",
            "           1       0.67      0.67      0.67       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.82      0.82     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8240038806385248 \n",
            "\n",
            "Epoch: 24, Loss:0.1220 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.68      0.72      0.70      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.85      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8462276928622539 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.64      0.69      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.83      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.83239629068397 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.68      0.67       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.83      0.82     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8281490549878422 \n",
            "\n",
            "Epoch: 25, Loss:0.1207 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.70      0.71      0.71      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.85      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8453911583840406 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.66      0.69      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.83      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8334388882413128 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.69      0.68      0.68       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.83      0.83      0.83     10763\n",
            "weighted avg       0.95      0.96      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8260041769498389 \n",
            "\n",
            "Epoch: 26, Loss:0.1183 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.71      0.72      0.71      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.85      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8474749960994453 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.67      0.68      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.83      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8298357746953153 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.70      0.68      0.69       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.83      0.83     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8266045972440448 \n",
            "\n",
            "Epoch: 27, Loss:0.1168 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.68      0.74      0.71      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.86      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8578454949938398 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.63      0.69      0.66       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.81      0.83      0.82      3587\n",
            "weighted avg       0.96      0.95      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8319494631593944 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.69      0.68       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.83      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8326444745087793 \n",
            "\n",
            "Epoch: 28, Loss:0.1149 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.67      0.75      0.71      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.86      0.84     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8632990084520985 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.62      0.70      0.66       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.80      0.84      0.82      3587\n",
            "weighted avg       0.96      0.95      0.95      3587\n",
            "\n",
            " Val_auc_roc: 0.8374286047324863 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.70      0.68       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.83      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.834591421787459 \n",
            "\n",
            "Epoch: 29, Loss:0.1131 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.70      0.74      0.72      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.86      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8606279355036559 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.66      0.70      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.84      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8376377718200775 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.69      0.69      0.69       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.83      0.83      0.83     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8325966488230073 \n",
            "\n",
            "Epoch: 30, Loss:0.1124 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.71      0.74      0.72      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.86      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8592676506824625 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.66      0.70      0.68       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.84      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8377867143282692 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.69      0.69      0.69       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.83      0.83      0.83     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8333460695213922 \n",
            "\n",
            "Epoch: 31, Loss:0.1102 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.68      0.76      0.72      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.87      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.865844523890225 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.62      0.71      0.67       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.80      0.84      0.82      3587\n",
            "weighted avg       0.96      0.95      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8417764308194428 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.70      0.68       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8362904032822976 \n",
            "\n",
            "Epoch: 32, Loss:0.1103 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.69      0.76      0.72      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.87      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8665557026109506 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.64      0.71      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.84      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8428190283767856 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      9993\n",
            "           1       0.67      0.70      0.68       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8361414028781187 \n",
            "\n",
            "Epoch: 33, Loss:0.1096 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.68      0.77      0.72      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.87      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8714102119211711 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      3357\n",
            "           1       0.62      0.71      0.66       230\n",
            "\n",
            "    accuracy                           0.95      3587\n",
            "   macro avg       0.80      0.84      0.82      3587\n",
            "weighted avg       0.96      0.95      0.95      3587\n",
            "\n",
            " Val_auc_roc: 0.841478545803059 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.71      0.68       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8396361219087127 \n",
            "\n",
            "Epoch: 34, Loss:0.1089 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.69      0.77      0.73      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.87      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8724706920391023 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.63      0.71      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.84      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8423722008522101 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      9993\n",
            "           1       0.67      0.71      0.69       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8390379109532516 \n",
            "\n",
            "Epoch: 35, Loss:0.1078 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.69      0.78      0.73      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.83      0.88      0.85     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8759273905020148 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.63      0.72      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.84      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8443971713874967 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97      9993\n",
            "           1       0.66      0.71      0.69       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.95      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.841235033354517 \n",
            "\n",
            "Epoch: 36, Loss:0.1071 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98     20040\n",
            "           1       0.69      0.78      0.73      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.84      0.88      0.86     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.875964714775301 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.64      0.71      0.67       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.81      0.84      0.82      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8426700858685939 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      9993\n",
            "           1       0.67      0.71      0.69       770\n",
            "\n",
            "    accuracy                           0.95     10763\n",
            "   macro avg       0.82      0.84      0.83     10763\n",
            "weighted avg       0.96      0.95      0.95     10763\n",
            "\n",
            " Test_auc_roc: 0.8421845941509707 \n",
            "\n",
            "Epoch: 37, Loss:0.1059 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.71      0.77      0.74      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.87      0.86     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8746790785006806 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.67      0.70      0.69       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.84      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8402585123881312 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.69      0.71      0.70       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.83      0.84      0.84     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8417876279629507 \n",
            "\n",
            "Epoch: 38, Loss:0.1047 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.72      0.77      0.74      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.88      0.86     21524\n",
            "weighted avg       0.96      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8751032301972874 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.68      0.71      0.69       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.83      0.84      0.84      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8428792529561849 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.70      0.71      0.70       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.84      0.84     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8422379431836051 \n",
            "\n",
            "Epoch: 39, Loss:0.1032 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.72      0.78      0.75      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.88      0.86     21524\n",
            "weighted avg       0.97      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8773992446374098 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.68      0.71      0.70       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.83      0.85      0.84      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8450531659996632 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.70      0.71      0.71       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.84      0.84     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8423880482571566 \n",
            "\n",
            "Epoch: 40, Loss:0.1015 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.72      0.78      0.75      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.88      0.86     21524\n",
            "weighted avg       0.97      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8789092300574054 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.67      0.72      0.70       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.83      0.85      0.84      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8488052220538524 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.70      0.71      0.71       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.84      0.84     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8443361002052087 \n",
            "\n",
            "Epoch: 41, Loss:0.1019 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.72      0.78      0.75      1484\n",
            "\n",
            "    accuracy                           0.96     21524\n",
            "   macro avg       0.85      0.88      0.87     21524\n",
            "weighted avg       0.97      0.96      0.96     21524\n",
            "\n",
            " Train_auc_roc: 0.8807810928009212 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      3357\n",
            "           1       0.66      0.72      0.69       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.82      0.85      0.83      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8460355389776069 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.69      0.72      0.71       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.84      0.85      0.84     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8475317137580721 \n",
            "\n",
            "Epoch: 42, Loss:0.0999 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.74      0.78      0.76      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.86      0.88      0.87     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8801942610735403 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.70      0.71      0.71       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.84      0.85      0.84      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8459468210488142 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.72      0.71      0.71       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.85      0.84      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8437879242742647 \n",
            "\n",
            "Epoch: 43, Loss:0.1000 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.75      0.78      0.76      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.86      0.88      0.87     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8783347725035104 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.72      0.71      0.71       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.85      0.84      0.85      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.844815505562679 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.72      0.71      0.71       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.85      0.84      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8427894331226664 \n",
            "\n",
            "Epoch: 44, Loss:0.0990 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.75      0.77      0.76      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.87      0.88      0.87     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8757764793862409 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.72      0.70      0.71       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.85      0.84      0.85      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8426415925192006 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.73      0.70      0.72       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.85      0.84      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8406923807704353 \n",
            "\n",
            "Epoch: 45, Loss:0.0971 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.74      0.78      0.76      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.86      0.88      0.87     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8811675167185845 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.70      0.71      0.70       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.84      0.84      0.84      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8437729080053361 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.73      0.71      0.72       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.85      0.85      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8460862213939367 \n",
            "\n",
            "Epoch: 46, Loss:0.0967 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     20040\n",
            "           1       0.78      0.76      0.77      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.88      0.87      0.88     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8735922360131488 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.73      0.70      0.72       230\n",
            "\n",
            "    accuracy                           0.96      3587\n",
            "   macro avg       0.85      0.84      0.85      3587\n",
            "weighted avg       0.96      0.96      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.843088420043776 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.76      0.70      0.73       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.87      0.84      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8396460639330648 \n",
            "\n",
            "Epoch: 47, Loss:0.0957 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     20040\n",
            "           1       0.81      0.76      0.78      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.90      0.87      0.88     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8714455186661717 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.74      0.70      0.72       230\n",
            "\n",
            "    accuracy                           0.97      3587\n",
            "   macro avg       0.86      0.84      0.85      3587\n",
            "weighted avg       0.96      0.97      0.96      3587\n",
            "\n",
            " Val_auc_roc: 0.8438331325847352 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.78      0.69      0.73       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.88      0.84      0.85     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8353518891795685 \n",
            "\n",
            "Epoch: 48, Loss:0.0958 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     20040\n",
            "           1       0.82      0.75      0.78      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.90      0.87      0.88     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.868650098724384 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      3357\n",
            "           1       0.77      0.70      0.74       230\n",
            "\n",
            "    accuracy                           0.97      3587\n",
            "   macro avg       0.88      0.85      0.86      3587\n",
            "weighted avg       0.97      0.97      0.97      3587\n",
            "\n",
            " Val_auc_roc: 0.84502467265027 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      9993\n",
            "           1       0.79      0.69      0.73       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.88      0.84      0.86     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8359022744492575 \n",
            "\n",
            "Epoch: 49, Loss:0.0950 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98     20040\n",
            "           1       0.80      0.77      0.79      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.89      0.88      0.88     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8765120029482815 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3357\n",
            "           1       0.75      0.71      0.73       230\n",
            "\n",
            "    accuracy                           0.97      3587\n",
            "   macro avg       0.86      0.85      0.85      3587\n",
            "weighted avg       0.97      0.97      0.97      3587\n",
            "\n",
            " Val_auc_roc: 0.8461559881364056 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      9993\n",
            "           1       0.78      0.70      0.73       770\n",
            "\n",
            "    accuracy                           0.96     10763\n",
            "   macro avg       0.88      0.84      0.86     10763\n",
            "weighted avg       0.96      0.96      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8403465542763051 \n",
            "\n",
            "Epoch: 50, Loss:0.0929 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     20040\n",
            "           1       0.84      0.74      0.79      1484\n",
            "\n",
            "    accuracy                           0.97     21524\n",
            "   macro avg       0.91      0.87      0.89     21524\n",
            "weighted avg       0.97      0.97      0.97     21524\n",
            "\n",
            " Train_auc_roc: 0.8665534833298363 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      3357\n",
            "           1       0.78      0.70      0.74       230\n",
            "\n",
            "    accuracy                           0.97      3587\n",
            "   macro avg       0.88      0.84      0.86      3587\n",
            "weighted avg       0.97      0.97      0.97      3587\n",
            "\n",
            " Val_auc_roc: 0.8412726165960809 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      9993\n",
            "           1       0.80      0.68      0.74       770\n",
            "\n",
            "    accuracy                           0.97     10763\n",
            "   macro avg       0.89      0.84      0.86     10763\n",
            "weighted avg       0.96      0.97      0.96     10763\n",
            "\n",
            " Test_auc_roc: 0.8357032390205611 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M7HALT0EBLrY",
        "7TzfhmvpBBxB",
        "U82jJWjW-6hO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/graph-tutorial/blob/master/Illegal_Bitcoin_Transactions2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--OwPLXN3oVj"
      },
      "source": [
        "# Applying GCNLPA to Illicit Bitcoin Transaction Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb7kHD6oJGTh"
      },
      "source": [
        "## Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SCIlBNn3vtc"
      },
      "source": [
        "This notebook contains the code required to recreate the models and the (partial) results in the blog. In particular, it includes the following:\n",
        "- Code to pre-process data and transofrm it into `torch_geometric.data.Data` format.\n",
        "- LPA model implemented using PyTorch.\n",
        "- GCN model implemented using PyTorch and PyTorch Geometric.\n",
        "- GCNLPA model implemented using PyTorch and PyTorch Geometric.\n",
        "- Code to train and perform hyperparamter optimization (using `optuna`) for each model.\n",
        "- Code to evaluate the performance of the best trained model for each model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfH1RRpuh2Ro"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjBejJf6_htC",
        "outputId": "ed6af595-4188-477e-f892-def22d527090"
      },
      "source": [
        "\n",
        "!pip install torch-geometric\n",
        "!pip install optuna"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=06c58de6c4e8c2c51211432fb59d8f95f0641e9770460b12e7984bbada388452\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjOQ1QJY_qij"
      },
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive, files\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Install Kaggle API.\n",
        "!pip install kaggle\n",
        "# 4.Run the following code to configure the path to “kaggle.json”\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!kaggle datasets download -d ellipticco/elliptic-data-set\n",
        "!unzip elliptic-data-set.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Pe_7E3sbPX",
        "outputId": "d18c6071-fb27-4958-f560-41a7c2d1097f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading elliptic-data-set.zip to /content\n",
            " 98% 143M/146M [00:05<00:00, 34.7MB/s]\n",
            "100% 146M/146M [00:05<00:00, 27.6MB/s]\n",
            "Archive:  elliptic-data-set.zip\n",
            "  inflating: elliptic_bitcoin_dataset/elliptic_txs_classes.csv  \n",
            "  inflating: elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv  \n",
            "  inflating: elliptic_bitcoin_dataset/elliptic_txs_features.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKFo4XjKP7vQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c4c7d1-654d-413f-ad9d-f0656356da6c"
      },
      "source": [
        "# set random seed\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f451ff7e550>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQSTICR6htxS"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ELN48Ln4ugf"
      },
      "source": [
        "We allow this notebook to access the Elliptic Bitcoin Dataset. To do so, first download the dataset from this [link](https://www.kaggle.com/ellipticco/elliptic-data-set) and unzip the file. Then, upload the folder to Google Drive. Then, modify the `data_folder` variable in the cell below to the appropriate path to the uploaded folder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPqBKZhY_1Iu"
      },
      "source": [
        "# specify path to folder on google drive that contains the data\n",
        "data_folder = '/content'\n",
        "\n",
        "# read in labels\n",
        "classes = pd.read_csv(data_folder + \"/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "# read in edge pairs\n",
        "edges = pd.read_csv(data_folder + \"/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
        "# read in features\n",
        "features = pd.read_csv(data_folder + \"/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`classes` contains a tuple of node ID and the class of the node. Notice that some nodes have class `unknown`. We want to drop these nodes later."
      ],
      "metadata": {
        "id": "StXK4YwMVOjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ob1zSaRiU8vJ",
        "outputId": "e3ec258d-4868-49b2-9f5d-d4981ca10a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        txId    class\n",
              "0  230425980  unknown\n",
              "1    5530458  unknown\n",
              "2  232022460  unknown"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-090d27f4-fbf6-4b04-aaff-903bef8d0ab8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232022460</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-090d27f4-fbf6-4b04-aaff-903bef8d0ab8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-090d27f4-fbf6-4b04-aaff-903bef8d0ab8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-090d27f4-fbf6-4b04-aaff-903bef8d0ab8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`edges` contains a pair of node IDs where $(v_1,v_2)\\in$ `edges` means that there is an edge from node $v_1$ to node $v_2$."
      ],
      "metadata": {
        "id": "fYRa_peJVY8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "vX_i-CH1VBOG",
        "outputId": "e880c2d1-f403-4235-cb21-a700a9380dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId1</th>\n",
              "      <th>txId2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>5530458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>232022460</td>\n",
              "      <td>232438397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>230460314</td>\n",
              "      <td>230459870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       txId1      txId2\n",
              "0  230425980    5530458\n",
              "1  232022460  232438397\n",
              "2  230460314  230459870"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`features` contains a vector of 166 features for each node. Feature `0` represents the node ID and feature `1` represents the timestamp. Other columns are actual features of the nodes."
      ],
      "metadata": {
        "id": "DFoQzDCtVwgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "51wfsyHlVBYZ",
        "outputId": "746dbbd3-bbdc-459d-d92f-2e9653a5e93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>230425980</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171469</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.12197</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162097</td>\n",
              "      <td>-0.167933</td>\n",
              "      <td>-0.049707</td>\n",
              "      <td>-0.164402</td>\n",
              "      <td>-0.028741</td>\n",
              "      <td>-0.035391</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.057195</td>\n",
              "      <td>-0.169609</td>\n",
              "      <td>-0.171154</td>\n",
              "      <td>-0.174473</td>\n",
              "      <td>-1.373657</td>\n",
              "      <td>-1.371460</td>\n",
              "      <td>-0.139731</td>\n",
              "      <td>-0.148912</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155661</td>\n",
              "      <td>-0.010763</td>\n",
              "      <td>-0.012107</td>\n",
              "      <td>-0.139733</td>\n",
              "      <td>-0.148907</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155661</td>\n",
              "      <td>-0.010669</td>\n",
              "      <td>-0.012005</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031272</td>\n",
              "      <td>-0.023045</td>\n",
              "      <td>-0.026215</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097719</td>\n",
              "      <td>-0.127462</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>-0.120950</td>\n",
              "      <td>-0.199145</td>\n",
              "      <td>-0.187993</td>\n",
              "      <td>-0.212948</td>\n",
              "      <td>1.064205</td>\n",
              "      <td>1.063787</td>\n",
              "      <td>-1.373782</td>\n",
              "      <td>-1.354735</td>\n",
              "      <td>-0.297975</td>\n",
              "      <td>-1.403698</td>\n",
              "      <td>1.342003</td>\n",
              "      <td>1.340733</td>\n",
              "      <td>-0.171601</td>\n",
              "      <td>-0.458162</td>\n",
              "      <td>-0.423588</td>\n",
              "      <td>-0.440883</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>-0.375715</td>\n",
              "      <td>0.759748</td>\n",
              "      <td>-0.768329</td>\n",
              "      <td>1.488113</td>\n",
              "      <td>1.487932</td>\n",
              "      <td>-0.216814</td>\n",
              "      <td>-0.605631</td>\n",
              "      <td>-0.562153</td>\n",
              "      <td>-0.600999</td>\n",
              "      <td>1.461330</td>\n",
              "      <td>1.461369</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5530458</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171484</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.12197</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162112</td>\n",
              "      <td>-0.167948</td>\n",
              "      <td>-0.049707</td>\n",
              "      <td>-0.164417</td>\n",
              "      <td>-0.028741</td>\n",
              "      <td>-0.035391</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.055327</td>\n",
              "      <td>-0.169757</td>\n",
              "      <td>-0.171477</td>\n",
              "      <td>-0.174490</td>\n",
              "      <td>0.887058</td>\n",
              "      <td>0.884557</td>\n",
              "      <td>-0.139731</td>\n",
              "      <td>-0.148912</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155661</td>\n",
              "      <td>-0.010763</td>\n",
              "      <td>-0.012107</td>\n",
              "      <td>-0.139733</td>\n",
              "      <td>-0.148907</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155661</td>\n",
              "      <td>-0.010669</td>\n",
              "      <td>-0.012005</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031272</td>\n",
              "      <td>-0.023045</td>\n",
              "      <td>-0.026215</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097719</td>\n",
              "      <td>-0.127462</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>-0.121330</td>\n",
              "      <td>-0.110933</td>\n",
              "      <td>-0.075909</td>\n",
              "      <td>-0.111641</td>\n",
              "      <td>-1.159649</td>\n",
              "      <td>-1.160129</td>\n",
              "      <td>-1.373723</td>\n",
              "      <td>-1.353918</td>\n",
              "      <td>-0.295982</td>\n",
              "      <td>-1.403215</td>\n",
              "      <td>-0.975738</td>\n",
              "      <td>-0.975237</td>\n",
              "      <td>-0.168742</td>\n",
              "      <td>-0.263290</td>\n",
              "      <td>-0.186389</td>\n",
              "      <td>-0.250875</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>0.146997</td>\n",
              "      <td>1.366287</td>\n",
              "      <td>-0.464773</td>\n",
              "      <td>-1.116918</td>\n",
              "      <td>-1.116948</td>\n",
              "      <td>-0.216814</td>\n",
              "      <td>0.634272</td>\n",
              "      <td>0.947382</td>\n",
              "      <td>0.673103</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.087490</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232022460</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172107</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.12197</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.113002</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.162749</td>\n",
              "      <td>-0.168576</td>\n",
              "      <td>-0.049707</td>\n",
              "      <td>-0.165054</td>\n",
              "      <td>-0.028741</td>\n",
              "      <td>-0.035391</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.055298</td>\n",
              "      <td>-0.170400</td>\n",
              "      <td>-0.172217</td>\n",
              "      <td>-0.175227</td>\n",
              "      <td>0.887058</td>\n",
              "      <td>0.884557</td>\n",
              "      <td>-0.139729</td>\n",
              "      <td>-0.148911</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155660</td>\n",
              "      <td>-0.010763</td>\n",
              "      <td>-0.012107</td>\n",
              "      <td>-0.139731</td>\n",
              "      <td>-0.148906</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155660</td>\n",
              "      <td>-0.010669</td>\n",
              "      <td>-0.012005</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031272</td>\n",
              "      <td>-0.023045</td>\n",
              "      <td>-0.026215</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097719</td>\n",
              "      <td>-0.129496</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>-0.122974</td>\n",
              "      <td>-0.041556</td>\n",
              "      <td>0.012549</td>\n",
              "      <td>-0.032244</td>\n",
              "      <td>-1.159649</td>\n",
              "      <td>-1.160129</td>\n",
              "      <td>-1.373902</td>\n",
              "      <td>-1.356210</td>\n",
              "      <td>-0.301548</td>\n",
              "      <td>-1.404577</td>\n",
              "      <td>-0.975738</td>\n",
              "      <td>-0.975237</td>\n",
              "      <td>-0.168742</td>\n",
              "      <td>-0.192468</td>\n",
              "      <td>-0.099790</td>\n",
              "      <td>-0.182133</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>-1.421138</td>\n",
              "      <td>-0.453330</td>\n",
              "      <td>-1.375441</td>\n",
              "      <td>-1.116918</td>\n",
              "      <td>-1.116948</td>\n",
              "      <td>-0.216814</td>\n",
              "      <td>0.407161</td>\n",
              "      <td>0.670883</td>\n",
              "      <td>0.439728</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>-0.098889</td>\n",
              "      <td>-0.106715</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.183671</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 167 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1         2         3    ...       163       164       165       166\n",
              "0  230425980    1 -0.171469 -0.184668  ... -0.131155 -0.097524 -0.120613 -0.119792\n",
              "1    5530458    1 -0.171484 -0.184668  ... -0.131155 -0.097524 -0.120613 -0.119792\n",
              "2  232022460    1 -0.172107 -0.184668  ... -0.131155 -0.183671 -0.120613 -0.119792\n",
              "\n",
              "[3 rows x 167 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "764YEgtT5euR"
      },
      "source": [
        "We clean the data. We drop unclassified nodes because our goal is to perform supervised classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd6jVepl5ZJD"
      },
      "source": [
        "# remap class, licit: 0, illicit: 1, unknown: -1\n",
        "classes[\"class\"] = classes[\"class\"].map({\"1\": 1, \"2\": 0, \"unknown\": -1})\n",
        "\n",
        "# merge features and labels\n",
        "df = features.merge(classes, how=\"left\", left_on=0, right_on=\"txId\")\n",
        "df = df.sort_values(0).reset_index(drop=True)\n",
        "assert len(df) == len(classes)\n",
        "\n",
        "# drop unclassified and isolated nodes\n",
        "classified_nodes = set(classes[classes[\"class\"] != -1][\"txId\"].values)\n",
        "assert len(classified_nodes) == 46564\n",
        "classified_edges = edges[(edges[\"txId1\"].isin(classified_nodes)) & (edges[\"txId2\"].isin(classified_nodes))].copy()\n",
        "non_isolated_nodes = set(classified_edges[\"txId1\"].values).union(classified_edges[\"txId2\"].values)\n",
        "classified_df = df[df[0].isin(non_isolated_nodes)].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hVcrgFI5uRq"
      },
      "source": [
        "We extract a subset of the data as the data is too large to be run on Google Colab with the provisioned compute instance. The data consists of multiple connected graphs, where each graph corresponds to bitcoin transactions at a particular timestamp. Hence, the subsetting is performed by choosing a subset of timestamps. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS70eokrCDvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e926c29d-01b0-4b6b-d7a8-ac48309450da"
      },
      "source": [
        "# only use nodes with timestamp 0 - 21\n",
        "# colab does not have enough memory to perform backpropagation when using all data\n",
        "# DO NOT RUN THIS FOR ACTUAL EXPERIMENT\n",
        "classified_nodes = set(classified_df[classified_df[1].between(0, 21)][0].values)\n",
        "classified_edges = edges.loc[(edges[\"txId1\"].isin(classified_nodes)) & (edges[\"txId2\"].isin(classified_nodes))].copy()\n",
        "non_isolated_nodes = set(classified_edges[\"txId1\"].values).union(classified_edges[\"txId2\"].values)\n",
        "classified_df = df[df[0].isin(non_isolated_nodes)].copy()\n",
        "print(len(non_isolated_nodes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5juOea-6K2u"
      },
      "source": [
        "We transform the data and store it as `torch_geometric.data.Data`. Realize that creating a `torch_geometric.data.Data` instance is straight forward: it suffices that we have tensors for the features, edge indices, and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__H8k97PCGRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "afccb1bd-0886-4cc5-d310-244436678c07"
      },
      "source": [
        "# reindex nodes\n",
        "classified_df = classified_df.sort_values(1).reset_index(drop=True)\n",
        "old2new = {old:new for new, old in enumerate(classified_df[0].values)}\n",
        "classified_edges[\"txId1\"] = classified_edges[\"txId1\"].map(old2new)\n",
        "classified_edges[\"txId2\"] = classified_edges[\"txId2\"].map(old2new)\n",
        "classified_df[0] = classified_df[0].map(old2new)\n",
        "\n",
        "classified_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172255</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.046932</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.02914</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.163581</td>\n",
              "      <td>-0.168790</td>\n",
              "      <td>-0.044161</td>\n",
              "      <td>-0.165578</td>\n",
              "      <td>-2.516705</td>\n",
              "      <td>-2.486106</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.053315</td>\n",
              "      <td>-0.170693</td>\n",
              "      <td>-0.172717</td>\n",
              "      <td>-0.175403</td>\n",
              "      <td>-1.373657</td>\n",
              "      <td>-1.37146</td>\n",
              "      <td>-0.139718</td>\n",
              "      <td>3.353530</td>\n",
              "      <td>4.932957</td>\n",
              "      <td>2.169850</td>\n",
              "      <td>-2.700912</td>\n",
              "      <td>-2.689592</td>\n",
              "      <td>-0.139720</td>\n",
              "      <td>3.353768</td>\n",
              "      <td>4.932954</td>\n",
              "      <td>2.170099</td>\n",
              "      <td>-2.700785</td>\n",
              "      <td>-2.689318</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031254</td>\n",
              "      <td>-0.022946</td>\n",
              "      <td>-0.026205</td>\n",
              "      <td>-6.996606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>-0.124152</td>\n",
              "      <td>-0.081143</td>\n",
              "      <td>-0.037443</td>\n",
              "      <td>-0.077985</td>\n",
              "      <td>-1.159649</td>\n",
              "      <td>-1.160129</td>\n",
              "      <td>-1.373902</td>\n",
              "      <td>-1.218610</td>\n",
              "      <td>0.057412</td>\n",
              "      <td>-1.328036</td>\n",
              "      <td>-0.975738</td>\n",
              "      <td>-0.975237</td>\n",
              "      <td>-0.168742</td>\n",
              "      <td>0.896507</td>\n",
              "      <td>1.231774</td>\n",
              "      <td>0.874856</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>0.669709</td>\n",
              "      <td>1.972826</td>\n",
              "      <td>-0.161217</td>\n",
              "      <td>-1.116918</td>\n",
              "      <td>-1.116948</td>\n",
              "      <td>-0.193143</td>\n",
              "      <td>2.899243</td>\n",
              "      <td>3.697427</td>\n",
              "      <td>3.006855</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>-0.098889</td>\n",
              "      <td>-0.08749</td>\n",
              "      <td>-0.084674</td>\n",
              "      <td>-0.140597</td>\n",
              "      <td>1.519700</td>\n",
              "      <td>1.521399</td>\n",
              "      <td>204236566</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.171546</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.046932</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.02914</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.163640</td>\n",
              "      <td>-0.168016</td>\n",
              "      <td>-0.036565</td>\n",
              "      <td>-0.165215</td>\n",
              "      <td>-2.516705</td>\n",
              "      <td>-2.486106</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.057328</td>\n",
              "      <td>-0.169678</td>\n",
              "      <td>-0.171222</td>\n",
              "      <td>-0.174563</td>\n",
              "      <td>-1.373657</td>\n",
              "      <td>-1.37146</td>\n",
              "      <td>-0.139732</td>\n",
              "      <td>-0.148912</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-2.700912</td>\n",
              "      <td>-2.689592</td>\n",
              "      <td>-0.139734</td>\n",
              "      <td>-0.148907</td>\n",
              "      <td>-0.080146</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-2.700785</td>\n",
              "      <td>-2.689318</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031272</td>\n",
              "      <td>-0.023045</td>\n",
              "      <td>-0.026215</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>-0.124499</td>\n",
              "      <td>-0.167579</td>\n",
              "      <td>-0.147106</td>\n",
              "      <td>-0.177400</td>\n",
              "      <td>-1.159649</td>\n",
              "      <td>-1.160129</td>\n",
              "      <td>-1.373693</td>\n",
              "      <td>-1.354814</td>\n",
              "      <td>-0.298387</td>\n",
              "      <td>-1.403698</td>\n",
              "      <td>1.342003</td>\n",
              "      <td>1.340733</td>\n",
              "      <td>-0.168742</td>\n",
              "      <td>-0.441084</td>\n",
              "      <td>-0.403790</td>\n",
              "      <td>-0.423447</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>0.146997</td>\n",
              "      <td>1.366287</td>\n",
              "      <td>-0.464773</td>\n",
              "      <td>-1.116918</td>\n",
              "      <td>-1.116948</td>\n",
              "      <td>-0.193143</td>\n",
              "      <td>-0.495145</td>\n",
              "      <td>-0.435113</td>\n",
              "      <td>-0.481158</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.08749</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>230528721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.172262</td>\n",
              "      <td>-0.184668</td>\n",
              "      <td>-1.201369</td>\n",
              "      <td>-0.046932</td>\n",
              "      <td>-0.043875</td>\n",
              "      <td>-0.02914</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.163641</td>\n",
              "      <td>-0.168737</td>\n",
              "      <td>-0.043146</td>\n",
              "      <td>-0.165581</td>\n",
              "      <td>-2.516705</td>\n",
              "      <td>-2.486106</td>\n",
              "      <td>-0.042955</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>-0.057341</td>\n",
              "      <td>-0.170413</td>\n",
              "      <td>-0.172066</td>\n",
              "      <td>-0.175411</td>\n",
              "      <td>-1.373657</td>\n",
              "      <td>-1.37146</td>\n",
              "      <td>-0.139732</td>\n",
              "      <td>-0.148912</td>\n",
              "      <td>-0.080147</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-2.700912</td>\n",
              "      <td>-2.689592</td>\n",
              "      <td>-0.139734</td>\n",
              "      <td>-0.148907</td>\n",
              "      <td>-0.080146</td>\n",
              "      <td>-0.155662</td>\n",
              "      <td>-2.700785</td>\n",
              "      <td>-2.689318</td>\n",
              "      <td>-0.024669</td>\n",
              "      <td>-0.031272</td>\n",
              "      <td>-0.023045</td>\n",
              "      <td>-0.026215</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.872194</td>\n",
              "      <td>-3.871849</td>\n",
              "      <td>-0.124848</td>\n",
              "      <td>-0.167579</td>\n",
              "      <td>-0.147027</td>\n",
              "      <td>-0.177472</td>\n",
              "      <td>-1.159649</td>\n",
              "      <td>-1.160129</td>\n",
              "      <td>-1.373693</td>\n",
              "      <td>-1.354814</td>\n",
              "      <td>-0.298387</td>\n",
              "      <td>-1.403698</td>\n",
              "      <td>1.342003</td>\n",
              "      <td>1.340733</td>\n",
              "      <td>-0.168742</td>\n",
              "      <td>-0.441084</td>\n",
              "      <td>-0.403790</td>\n",
              "      <td>-0.423447</td>\n",
              "      <td>-1.015963</td>\n",
              "      <td>-1.01623</td>\n",
              "      <td>-0.968903</td>\n",
              "      <td>0.146997</td>\n",
              "      <td>1.366287</td>\n",
              "      <td>-0.464773</td>\n",
              "      <td>-1.116918</td>\n",
              "      <td>-1.116948</td>\n",
              "      <td>-0.193143</td>\n",
              "      <td>-0.495145</td>\n",
              "      <td>-0.435113</td>\n",
              "      <td>-0.481158</td>\n",
              "      <td>-0.979074</td>\n",
              "      <td>-0.978556</td>\n",
              "      <td>0.018279</td>\n",
              "      <td>-0.08749</td>\n",
              "      <td>-0.131155</td>\n",
              "      <td>-0.097524</td>\n",
              "      <td>-0.120613</td>\n",
              "      <td>-0.119792</td>\n",
              "      <td>230528722</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 169 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1         2         3  ...       165       166       txId  class\n",
              "0  0  1 -0.172255 -0.184668  ...  1.519700  1.521399  204236566      0\n",
              "1  1  1 -0.171546 -0.184668  ... -0.120613 -0.119792  230528721      0\n",
              "2  2  1 -0.172262 -0.184668  ... -0.120613 -0.119792  230528722      0\n",
              "\n",
              "[3 rows x 169 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# edges\n",
        "edge_index = torch.tensor(classified_edges.values, dtype=torch.long)\n",
        "edge_index = edge_index.t().contiguous()\n",
        "\n",
        "# labels \n",
        "labels = classified_df[\"class\"].values\n",
        "labels = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "# timestamps \n",
        "timestamps = set(classified_df[1].values)\n",
        "\n",
        "# features\n",
        "features = torch.tensor(classified_df.drop([0, 1, \"class\", \"txId\"], axis=1).values, dtype=torch.float)\n",
        "\n",
        "# construct torch_geometric.data.Data\n",
        "data = Data(x=features, edge_index=edge_index, y=labels)\n",
        "\n",
        "# visualize data\n",
        "# this takes too long with the current size of the data\n",
        "# g = torch_geometric.utils.to_networkx(data, to_undirected=False)\n",
        "# plt.figure(figsize=(14,10))\n",
        "# nx.draw(g, alpha=0.5, node_color=labels)"
      ],
      "metadata": {
        "id": "gsYmYpmsUkgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfWuNlT36mLL"
      },
      "source": [
        "Lastly, we split the data into train/validation/test sets with 0.7/0.15/0.15 ratio. We use a stratified split because the labels are extremely imbalanced (there are far less fraudulant nodes than non-fraudulant nodes) and we want to make sure that each partition contains enough fraudulant nodes. Moreover, we do not split according to the timestamps. This is because nodes from different timestamps are disconnected, which means that if we split by timestamps, then we cannot \"learn\" edge weights for graphs in the validation/test sets during the training of GCNLPA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvyE6W9MCZ38"
      },
      "source": [
        "# generate array of indices\n",
        "indices = np.arange(len(labels))\n",
        "\n",
        "# split indices into train, val, and test sets\n",
        "train_indices, test_indices, train_labels, test_labels = train_test_split(indices, labels, test_size=0.3, stratify=labels, random_state=42) \n",
        "val_indices, test_indices, val_labels, test_labels = train_test_split(test_indices, test_labels, test_size=0.5, stratify=test_labels, random_state=42) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEr2wHnHhxhP"
      },
      "source": [
        "## GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7HALT0EBLrY"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUb-9wqr8ILG"
      },
      "source": [
        "This is the implementation of GCN using PyTorch and PyTorch Geometric. Our model consists of multiple layers of `GCNConv`, each of which is connected by a batch normalization and dropout components. The output is passed through a softmax layer being being returned to obtain propabilities. \n",
        "\n",
        "Notice that the implementation is relatively simple: we basically just have to import `GCNConv` from PyTorch Geometric and use it just like any other layer typically found in neural networks such as a linear layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz7Izr43C-1B"
      },
      "source": [
        "# GCN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "        \n",
        "        convs = [GCNConv(input_dim, hidden_dim)] + [GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers-2)] + [GCNConv(hidden_dim, output_dim)]\n",
        "        self.convs = torch.nn.ModuleList(convs)\n",
        "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim) for _ in range(num_layers-1)])\n",
        "        self.dropout = dropout\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, data, adj_t=None):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        for i, layer in enumerate(self.convs):\n",
        "          x = layer(x, edge_index)\n",
        "          if i < len(self.convs)-1:\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        out = self.softmax(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX3UdCL0BIaN"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSZIwt6N8vz6"
      },
      "source": [
        "The below cell trains and evaluates the GCN model implemented above. Our procedure is as follows:\n",
        "- Sample a set of hyperparameters from a predefined hyperparameter space.\n",
        "- Train the model using the sampled set of hyperparamters using the train set.\n",
        "- Evaluate the trained model using the validation set.\n",
        "- Save the model paramters. \n",
        "- Choose the trained model with the best validation performance. Evaluate this model using the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhja-MpG7b_A"
      },
      "source": [
        "DEVICE = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda:0\"\n",
        "\n",
        "def define_gcn(trial):\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
        "  hidden_dim = trial.suggest_int(\"hidden_dim\", 2**5, 2**8, log=True)\n",
        "  dropout = trial.suggest_float(\"dropout\", 0.3, 0.7)\n",
        "  return GCN(165,hidden_dim,2,n_layers,dropout)\n",
        "  \n",
        "def objective_gcn(trial, data):\n",
        "  model = define_gcn(trial).to(DEVICE)\n",
        "\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  t = trial.suggest_float(\"t\", 0.2, 0.6)\n",
        "\n",
        "  for epoch in range(100):\n",
        "\n",
        "    model.train()\n",
        "    data = data.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "\n",
        "    tmp = torch.nn.functional.one_hot(data.y.type(torch.long)).type(torch.float)\n",
        "    loss = criterion(out[train_indices], tmp[train_indices])\n",
        "    y = out.detach()[:, 1]\n",
        "    y = (y > t).type(torch.long)\n",
        "    f1 = f1_score(data.y.cpu()[train_indices], y.cpu()[train_indices])\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      valf1 = f1_score(data.y.cpu()[val_indices], y.cpu()[val_indices])\n",
        "    trial.report(valf1, epoch)\n",
        "\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.TrialPruned()\n",
        "  \n",
        "  torch.save(model.state_dict(), \"gcn-\" + str(trial.number) + \".pth\")\n",
        "  return valf1\n",
        "\n",
        "def eval_gcn():\n",
        "\n",
        "  # train and optimize hyperparameters\n",
        "  study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
        "  study.optimize(\n",
        "      lambda trial: objective_gcn(trial, data), n_trials=100, timeout=10000,\n",
        "  )\n",
        "\n",
        "  # result of hyperparamter optimization\n",
        "  pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "  complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "  print(\"Study statistics: \")\n",
        "  print(\"  Number of finished trials: \", len(study.trials))\n",
        "  print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "  print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "  # retrieve best trial from hyperparameter optimization\n",
        "  print(\"Best trial:\")\n",
        "  trial = study.best_trial\n",
        "  print(\"  Value: \", trial.value)\n",
        "  print(\"  Params: \")\n",
        "  for key, value in trial.params.items():\n",
        "      print(\"    {}: {}\".format(key, value))\n",
        "  print(\"\\t Trial number: \", trial.number)\n",
        "\n",
        "  # reconstruct best trained model\n",
        "  state_dict = torch.load(\"gcn-\" + str(trial.number) + \".pth\")\n",
        "  files.download(\"gcn-\" + str(trial.number) + \".pth\")\n",
        "  model = GCN(165,trial.params[\"hidden_dim\"],2,trial.params[\"n_layers\"],trial.params[\"dropout\"])\n",
        "  model.load_state_dict(state_dict)\n",
        "\n",
        "  # evaluate best trained model using test set\n",
        "  model.to(DEVICE)\n",
        "  model.eval()\n",
        "  out = model(data)\n",
        "  tmp = torch.nn.functional.one_hot(data.y.type(torch.long)).type(torch.float)\n",
        "  y = out.detach()[:, 1]\n",
        "  y = (y > trial.params[\"t\"]).type(torch.long)\n",
        "  f1 = f1_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  acc = accuracy_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  pre = precision_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  rec = recall_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  print(\"test performance:\")\n",
        "  print(f\"\\t f1: {f1}\")\n",
        "  print(f\"\\t acc: {acc}\")\n",
        "  print(f\"\\t pre: {pre}\")\n",
        "  print(f\"\\t rec: {rec}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1cWLTnSHF8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18bad21d-f738-4df8-fe97-cf85ec3a5479"
      },
      "source": [
        "eval_gcn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-08 07:33:24,655]\u001b[0m A new study created in memory with name: no-name-75cb930a-dd48-49af-8684-0f6bba8409d9\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:37,433]\u001b[0m Trial 0 finished with value: 0.13646055437100213 and parameters: {'n_layers': 3, 'hidden_dim': 231, 'dropout': 0.592797576724562, 'optimizer': 'Adam', 'lr': 0.00013066739238053285, 't': 0.546470458309974}. Best is trial 0 with value: 0.13646055437100213.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:40,724]\u001b[0m Trial 1 finished with value: 0.16411682892906815 and parameters: {'n_layers': 4, 'hidden_dim': 139, 'dropout': 0.308233797718321, 'optimizer': 'Adam', 'lr': 0.0002310201887845295, 't': 0.27336180394137355}. Best is trial 1 with value: 0.16411682892906815.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:42,860]\u001b[0m Trial 2 finished with value: 0.26499999999999996 and parameters: {'n_layers': 3, 'hidden_dim': 95, 'dropout': 0.4727780074568463, 'optimizer': 'RMSprop', 'lr': 0.0003839629299804173, 't': 0.3465447373174767}. Best is trial 2 with value: 0.26499999999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:45,548]\u001b[0m Trial 3 finished with value: 0.6319018404907976 and parameters: {'n_layers': 3, 'hidden_dim': 163, 'dropout': 0.37986951286334386, 'optimizer': 'RMSprop', 'lr': 0.0016409286730647919, 't': 0.2682096494749166}. Best is trial 3 with value: 0.6319018404907976.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:47,632]\u001b[0m Trial 4 finished with value: 0.5745454545454545 and parameters: {'n_layers': 2, 'hidden_dim': 230, 'dropout': 0.6862528132298237, 'optimizer': 'Adam', 'lr': 0.0023359635026261607, 't': 0.37606099749584054}. Best is trial 3 with value: 0.6319018404907976.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:47,738]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:47,768]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,245]\u001b[0m Trial 7 finished with value: 0.6821705426356588 and parameters: {'n_layers': 2, 'hidden_dim': 48, 'dropout': 0.3180909155642152, 'optimizer': 'RMSprop', 'lr': 0.004544383960336014, 't': 0.3427013306774357}. Best is trial 7 with value: 0.6821705426356588.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,278]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,304]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,344]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,375]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,409]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,447]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:49,484]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,567]\u001b[0m Trial 15 finished with value: 0.4285714285714286 and parameters: {'n_layers': 3, 'hidden_dim': 76, 'dropout': 0.4291927350987214, 'optimizer': 'RMSprop', 'lr': 0.004160617933755996, 't': 0.21325804366533557}. Best is trial 7 with value: 0.6821705426356588.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,629]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,791]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,843]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,896]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,928]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:51,968]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:52,010]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:52,192]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:54,121]\u001b[0m Trial 24 finished with value: 0.4919093851132686 and parameters: {'n_layers': 2, 'hidden_dim': 130, 'dropout': 0.6305789282933288, 'optimizer': 'Adam', 'lr': 0.006427682164753891, 't': 0.33649966336958487}. Best is trial 7 with value: 0.6821705426356588.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:54,187]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,444]\u001b[0m Trial 26 finished with value: 0.7490909090909091 and parameters: {'n_layers': 2, 'hidden_dim': 197, 'dropout': 0.3449548283415304, 'optimizer': 'RMSprop', 'lr': 0.0022270549046375598, 't': 0.438817870015776}. Best is trial 26 with value: 0.7490909090909091.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,487]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,530]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,574]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,604]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:56,650]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:58,682]\u001b[0m Trial 32 finished with value: 0.6974789915966385 and parameters: {'n_layers': 2, 'hidden_dim': 153, 'dropout': 0.42303560210617697, 'optimizer': 'RMSprop', 'lr': 0.0012762998744671509, 't': 0.42764274257999324}. Best is trial 26 with value: 0.7490909090909091.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:58,727]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:58,776]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:58,819]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:33:58,867]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:00,698]\u001b[0m Trial 37 finished with value: 0.7528517110266161 and parameters: {'n_layers': 2, 'hidden_dim': 99, 'dropout': 0.41528211684678334, 'optimizer': 'RMSprop', 'lr': 0.001846906251904492, 't': 0.4300290296471279}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:00,736]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:00,774]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:02,564]\u001b[0m Trial 40 finished with value: 0.7247386759581881 and parameters: {'n_layers': 2, 'hidden_dim': 94, 'dropout': 0.37432737289529183, 'optimizer': 'RMSprop', 'lr': 0.0018609144180868772, 't': 0.40540630933865}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:02,600]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:02,634]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:02,669]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,263]\u001b[0m Trial 44 finished with value: 0.7054794520547945 and parameters: {'n_layers': 2, 'hidden_dim': 58, 'dropout': 0.4421839592345086, 'optimizer': 'RMSprop', 'lr': 0.0021486154999531336, 't': 0.40033005026361373}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,297]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,335]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,369]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,422]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,466]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,510]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:04,546]\u001b[0m Trial 51 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,122]\u001b[0m Trial 52 finished with value: 0.676829268292683 and parameters: {'n_layers': 2, 'hidden_dim': 42, 'dropout': 0.401160637606022, 'optimizer': 'RMSprop', 'lr': 0.0029460789836394056, 't': 0.3242956726730087}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,158]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,196]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,241]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,273]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:06,318]\u001b[0m Trial 57 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,298]\u001b[0m Trial 58 finished with value: 0.6772151898734177 and parameters: {'n_layers': 2, 'hidden_dim': 123, 'dropout': 0.38917523524257236, 'optimizer': 'RMSprop', 'lr': 0.0017543889177439914, 't': 0.29754891461653754}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,337]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,382]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,425]\u001b[0m Trial 61 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,465]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,517]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,562]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,597]\u001b[0m Trial 65 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,636]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,672]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,831]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:08,907]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:09,037]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:09,085]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:09,120]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:09,159]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:09,192]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:10,803]\u001b[0m Trial 75 finished with value: 0.6746987951807228 and parameters: {'n_layers': 2, 'hidden_dim': 54, 'dropout': 0.31917810191188584, 'optimizer': 'RMSprop', 'lr': 0.0044213219417819005, 't': 0.2913967876255925}. Best is trial 37 with value: 0.7528517110266161.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:10,871]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:10,951]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:10,993]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,030]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,103]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,139]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,269]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,310]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,343]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,376]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,410]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,450]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,506]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,546]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,582]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:11,643]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:12,986]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,048]\u001b[0m Trial 93 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,088]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,147]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,187]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,224]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,259]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:34:13,303]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  84\n",
            "  Number of complete trials:  16\n",
            "Best trial:\n",
            "  Value:  0.7528517110266161\n",
            "  Params: \n",
            "    n_layers: 2\n",
            "    hidden_dim: 99\n",
            "    dropout: 0.41528211684678334\n",
            "    optimizer: RMSprop\n",
            "    lr: 0.001846906251904492\n",
            "    t: 0.4300290296471279\n",
            "\t Trial number:  37\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5794df0c-748a-4983-b078-dd857a40b890\", \"gcn-37.pth\", 71179)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test performance:\n",
            "\t f1: 0.7449392712550608\n",
            "\t acc: 0.9725729212015672\n",
            "\t pre: 0.8518518518518519\n",
            "\t rec: 0.6618705035971223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5fMAF9ShzyM"
      },
      "source": [
        "## GCNLPA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TzfhmvpBBxB"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uTpuolz-KEa"
      },
      "source": [
        "This is the implementation of GCNLPA. The GCN part is essentially the same as the earlier GCN model. The main differences here are that we have `edge_weight` as trainable parameters and add LPA in the `forward` function.\n",
        "\n",
        "GCN and GCNLPA are non-trivially different. However, GCNLPA is still relatively straight forward to implement using PyTorch and PyTorch Geometric. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPH7uxus2e-I"
      },
      "source": [
        "class GCNLPA(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, edge_dim, k):\n",
        "        super(GCNLPA, self).__init__()\n",
        "        \n",
        "        convs = [GCNConv(input_dim, hidden_dim)] + [GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers-2)] + [GCNConv(hidden_dim, output_dim)]\n",
        "        self.convs = torch.nn.ModuleList(convs)\n",
        "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim) for _ in range(num_layers-1)])\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.dropout = dropout\n",
        "        self.edge_weight = torch.nn.Parameter(torch.ones(edge_dim))\n",
        "        self.k = k\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, data, adj_t=None):\n",
        "        # GCN\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        for i, layer in enumerate(self.convs):\n",
        "          x = layer(x, edge_index, self.edge_weight.sigmoid())\n",
        "          if i < len(self.convs)-1:\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        out = self.softmax(x)\n",
        "\n",
        "        # LPA implementation with dense format\n",
        "        labels = torch.nn.functional.one_hot(data.y.type(torch.long)).type(torch.float)\n",
        "        matrix = torch_geometric.utils.to_dense_adj(data.edge_index, edge_attr=self.edge_weight.sigmoid(), max_num_nodes=data.num_nodes)\n",
        "        matrix = matrix.squeeze(0)\n",
        "        selfloop = torch.diag(torch.ones(matrix.shape[0])).to(DEVICE)\n",
        "        matrix += selfloop\n",
        "        for _ in range(self.k):\n",
        "          y = torch.matmul(matrix, labels)\n",
        "          labels = y\n",
        "        return out, torch.nn.functional.normalize(labels, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znU9dGg6BEI7"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXbPT0IO-0Bk"
      },
      "source": [
        "The below cell trains and evaluates the GCNLPA model implemented above. The procedure is identical to the earlier procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PYDbtxDIe0Z"
      },
      "source": [
        "DEVICE = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda:0\"\n",
        "\n",
        "def define_gcnlpa(trial, edge_dim):\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
        "  hidden_dim = trial.suggest_int(\"hidden_dim\", 2**5, 2**8, log=True)\n",
        "  dropout = trial.suggest_float(\"dropout\", 0.3, 0.7)\n",
        "  k = trial.suggest_int(\"k\", 3, 7)\n",
        "  return GCNLPA(165,hidden_dim,2,n_layers,dropout,edge_dim,k)\n",
        "  \n",
        "def objective_gcnlpa(trial, data):\n",
        "  model = define_gcnlpa(trial, data.num_edges).to(DEVICE)\n",
        "\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "  optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  criterion = torch.nn.BCELoss()\n",
        "  criterion_lpa = torch.nn.BCELoss()\n",
        "  t = trial.suggest_float(\"t\", 0.2, 0.6)\n",
        "  lambda_ = trial.suggest_int(\"lambda_\", 1, 10)\n",
        "\n",
        "  for epoch in range(100):\n",
        "\n",
        "    model.train()\n",
        "    data = data.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    out, out_lpa = model(data)\n",
        "\n",
        "    tmp = torch.nn.functional.one_hot(data.y.type(torch.long)).type(torch.float)\n",
        "    loss = criterion(out[train_indices], tmp[train_indices])\n",
        "    loss_lpa = criterion(out_lpa[train_indices], tmp[train_indices])\n",
        "    loss += lambda_ * loss_lpa\n",
        "    y = out.detach()[:, 1]\n",
        "    y = (y > t).type(torch.long)\n",
        "    f1 = f1_score(data.y.cpu()[train_indices], y.cpu()[train_indices])\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      valf1 = f1_score(data.y.cpu()[val_indices], y.cpu()[val_indices])\n",
        "    trial.report(valf1, epoch)\n",
        "\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.TrialPruned()\n",
        "  \n",
        "  torch.save(model.state_dict(), \"gcnlpa-\" + str(trial.number) + \".pth\")\n",
        "  return valf1\n",
        "\n",
        "def eval_gcnlpa():\n",
        "\n",
        "  # train and optimize hyperparameters\n",
        "  study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
        "  study.optimize(\n",
        "      lambda trial: objective_gcnlpa(trial, data), n_trials=100, timeout=10000,\n",
        "  )\n",
        "\n",
        "  # result of hyperparameter optimization\n",
        "  pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "  complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "  print(\"Study statistics: \")\n",
        "  print(\"  Number of finished trials: \", len(study.trials))\n",
        "  print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "  print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "  # retrieve best trial from hyperparameter optimization\n",
        "  print(\"Best trial:\")\n",
        "  trial = study.best_trial\n",
        "  print(\"  Value: \", trial.value)\n",
        "  print(\"  Params: \")\n",
        "  for key, value in trial.params.items():\n",
        "      print(\"    {}: {}\".format(key, value))\n",
        "  print(\"\\t Trial number: \", trial.number)\n",
        "\n",
        "  # reconstruct best trained model\n",
        "  state_dict = torch.load(\"gcnlpa-\" + str(trial.number) + \".pth\")\n",
        "  files.download(\"gcnlpa-\" + str(trial.number) + \".pth\")\n",
        "  model = GCNLPA(165,trial.params[\"hidden_dim\"],2,trial.params[\"n_layers\"],trial.params[\"dropout\"],data.num_edges,trial.params[\"k\"])\n",
        "  model.load_state_dict(state_dict)\n",
        "\n",
        "  # evaluate best trained model using test set\n",
        "  model.to(DEVICE)\n",
        "  model.eval()\n",
        "  out, _ = model(data)\n",
        "  tmp = torch.nn.functional.one_hot(data.y.type(torch.long)).type(torch.float)\n",
        "  y = out.detach()[:, 1]\n",
        "  y = (y > trial.params[\"t\"]).type(torch.long)\n",
        "  f1 = f1_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  acc = accuracy_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  pre = precision_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  rec = recall_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "  print(\"test performance:\")\n",
        "  print(f\"\\t f1: {f1}\")\n",
        "  print(f\"\\t acc: {acc}\")\n",
        "  print(f\"\\t pre: {pre}\")\n",
        "  print(f\"\\t rec: {rec}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DalJ4J5jRSXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb8f352-2860-4431-a3ea-9e1148f3f335"
      },
      "source": [
        "eval_gcnlpa()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-08 07:34:13,602]\u001b[0m A new study created in memory with name: no-name-b6a40409-f436-41b9-8e72-b609b947953c\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:35:28,059]\u001b[0m Trial 0 finished with value: 0.25641025641025644 and parameters: {'n_layers': 3, 'hidden_dim': 231, 'dropout': 0.592797576724562, 'k': 5, 'optimizer': 'Adam', 'lr': 0.005399484409787433, 't': 0.4404460046972835, 'lambda_': 8}. Best is trial 0 with value: 0.25641025641025644.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:36:34,871]\u001b[0m Trial 1 finished with value: 0.20416666666666666 and parameters: {'n_layers': 2, 'hidden_dim': 241, 'dropout': 0.6329770563201687, 'k': 4, 'optimizer': 'SGD', 'lr': 0.0011207606211860567, 't': 0.3727780074568463, 'lambda_': 3}. Best is trial 0 with value: 0.25641025641025644.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:37:42,017]\u001b[0m Trial 2 finished with value: 0.13872832369942195 and parameters: {'n_layers': 4, 'hidden_dim': 42, 'dropout': 0.41685785941408726, 'k': 4, 'optimizer': 'RMSprop', 'lr': 0.0010677482709481358, 't': 0.43696582754481694, 'lambda_': 1}. Best is trial 0 with value: 0.25641025641025644.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:39:07,829]\u001b[0m Trial 3 finished with value: 0.0967741935483871 and parameters: {'n_layers': 4, 'hidden_dim': 45, 'dropout': 0.3260206371941118, 'k': 7, 'optimizer': 'Adam', 'lr': 0.0001567993391672301, 't': 0.47369321060486275, 'lambda_': 5}. Best is trial 0 with value: 0.25641025641025644.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:32,333]\u001b[0m Trial 4 finished with value: 0.7601476014760148 and parameters: {'n_layers': 2, 'hidden_dim': 89, 'dropout': 0.31375540844608735, 'k': 7, 'optimizer': 'RMSprop', 'lr': 0.001096821720752952, 't': 0.41868411173731185, 'lambda_': 2}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:34,094]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:35,439]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:37,166]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:37,801]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:39,260]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:40,066]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:41,681]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:42,455]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:43,262]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:44,022]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:45,637]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:46,323]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:46,976]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:47,731]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:49,331]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:50,210]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:50,900]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:52,262]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:53,758]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:54,404]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:55,752]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:57,252]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:57,996]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:58,636]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:40:59,355]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:00,969]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:02,331]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:03,700]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:05,496]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:06,864]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:07,515]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:08,997]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:09,708]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:10,566]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:11,812]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:12,573]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:13,458]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:14,344]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:15,168]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:16,052]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:16,888]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:17,757]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:19,372]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:20,062]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:21,588]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:22,398]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:23,931]\u001b[0m Trial 51 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:25,480]\u001b[0m Trial 52 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:41:27,003]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:36,714]\u001b[0m Trial 54 finished with value: 0.6824324324324325 and parameters: {'n_layers': 4, 'hidden_dim': 232, 'dropout': 0.38051423793198474, 'k': 4, 'optimizer': 'Adam', 'lr': 0.008272329468551118, 't': 0.3027174280605876, 'lambda_': 3}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:37,427]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:38,141]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:39,502]\u001b[0m Trial 57 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:40,737]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:42,106]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:42,998]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:43,803]\u001b[0m Trial 61 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:42:45,360]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:43:55,209]\u001b[0m Trial 63 finished with value: 0.6456140350877192 and parameters: {'n_layers': 4, 'hidden_dim': 211, 'dropout': 0.3223333541960547, 'k': 4, 'optimizer': 'Adam', 'lr': 0.002116090831360014, 't': 0.28771625728370287, 'lambda_': 5}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:43:55,938]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:43:56,659]\u001b[0m Trial 65 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:43:57,409]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:43:58,070]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:45:05,388]\u001b[0m Trial 68 finished with value: 0.7235772357723578 and parameters: {'n_layers': 2, 'hidden_dim': 190, 'dropout': 0.6533086016669817, 'k': 4, 'optimizer': 'RMSprop', 'lr': 0.0014468171365724077, 't': 0.4201802299732667, 'lambda_': 1}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:45:06,078]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:13,160]\u001b[0m Trial 70 finished with value: 0.7243589743589745 and parameters: {'n_layers': 2, 'hidden_dim': 218, 'dropout': 0.6260322629190518, 'k': 4, 'optimizer': 'RMSprop', 'lr': 0.0008692161331903813, 't': 0.20078302659608807, 'lambda_': 1}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:13,858]\u001b[0m Trial 71 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:19,247]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:20,601]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:21,303]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:22,000]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:22,640]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:28,005]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:28,696]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:29,353]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:30,043]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:30,922]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:32,275]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:33,190]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:33,885]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:34,596]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:35,425]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:36,924]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:38,278]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:38,934]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:40,536]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:41,908]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:47,306]\u001b[0m Trial 92 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:46:52,721]\u001b[0m Trial 93 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:47:59,805]\u001b[0m Trial 94 finished with value: 0.6784660766961651 and parameters: {'n_layers': 2, 'hidden_dim': 201, 'dropout': 0.3300420697456547, 'k': 4, 'optimizer': 'RMSprop', 'lr': 0.0005693429634288825, 't': 0.20075712425524078, 'lambda_': 1}. Best is trial 4 with value: 0.7601476014760148.\u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:48:00,514]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:48:01,421]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:48:02,943]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:48:03,631]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "\u001b[32m[I 2021-12-08 07:48:05,017]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  90\n",
            "  Number of complete trials:  10\n",
            "Best trial:\n",
            "  Value:  0.7601476014760148\n",
            "  Params: \n",
            "    n_layers: 2\n",
            "    hidden_dim: 89\n",
            "    dropout: 0.31375540844608735\n",
            "    k: 7\n",
            "    optimizer: RMSprop\n",
            "    lr: 0.001096821720752952\n",
            "    t: 0.41868411173731185\n",
            "    lambda_: 2\n",
            "\t Trial number:  4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b234cb2f-05e5-43b4-965a-eb597c9c9b0c\", \"gcnlpa-4.pth\", 122759)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test performance:\n",
            "\t f1: 0.7795275590551182\n",
            "\t acc: 0.9756203744013932\n",
            "\t pre: 0.8608695652173913\n",
            "\t rec: 0.7122302158273381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWZLg9lMh65Q"
      },
      "source": [
        "## LPA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U82jJWjW-6hO"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrgIqt4Ih77k"
      },
      "source": [
        "class LPA():\n",
        "  def __init__(self, data, to_undirected = False):\n",
        "    if data.is_directed() and to_undirected:\n",
        "      edge_index = torch_geometric.utils.to_undirected(data.edge_index)\n",
        "      data = Data(x=data.x, edge_index=edge_index, y=data.y)\n",
        "    self.data = data\n",
        "  \n",
        "  def predict(self, k):\n",
        "    A = torch_geometric.utils.to_dense_adj(self.data.edge_index, max_num_nodes=self.data.num_nodes).squeeze(0).to(DEVICE)\n",
        "    selfloop = torch.diag(torch.ones(A.shape[0])).to(DEVICE)\n",
        "    A += selfloop\n",
        "    D = torch.diag(torch.sum(A, dim=1))\n",
        "    D_inverse = torch.inverse(D).to(DEVICE)\n",
        "    Y = self.data.y.clone().type(torch.LongTensor)\n",
        "    Y[val_indices] = torch.zeros(len(val_indices)).type(torch.LongTensor)\n",
        "    Y[test_indices] = torch.zeros(len(test_indices)).type(torch.LongTensor)\n",
        "    Y = torch.nn.functional.one_hot(Y).type(torch.FloatTensor).to(DEVICE)\n",
        "    for _ in range(k):\n",
        "      Y_new = torch.matmul(torch.matmul(D_inverse, A), Y)\n",
        "      Y_new[train_indices] = Y[train_indices]\n",
        "      Y = Y_new\n",
        "    Y = torch.argmax(Y, dim=1)\n",
        "    self.prediction = Y[val_indices]\n",
        "    self.target = self.data.y[val_indices]\n",
        "    return Y "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ejU9jPzBSkb"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74k5RgUbjdmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39fb1a5-8e2f-40af-e021-099210612890"
      },
      "source": [
        "DEVICE = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda:0\"\n",
        "\n",
        "f1s = []\n",
        "for k in range(3, 7):\n",
        "  lpa = LPA(data, to_undirected=True)\n",
        "  y = lpa.predict(k)\n",
        "  f1 = f1_score(data.y.cpu()[val_indices], y.cpu()[val_indices])\n",
        "  f1s.append(f1)\n",
        "  print(k, f\"\\t f1: {f1}\")\n",
        "\n",
        "j = 3 + np.argmax(f1s)\n",
        "y = lpa.predict(j)\n",
        "f1 = f1_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "acc = accuracy_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "pre = precision_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "rec = recall_score(data.y.cpu()[test_indices], y.cpu()[test_indices])\n",
        "print(\"test performance:\")\n",
        "print(f\"\\t f1: {f1}\")\n",
        "print(f\"\\t acc: {acc}\")\n",
        "print(f\"\\t pre: {pre}\")\n",
        "print(f\"\\t rec: {rec}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 \t f1: 0.3174603174603175\n",
            "4 \t f1: 0.33507853403141363\n",
            "5 \t f1: 0.37810945273631846\n",
            "6 \t f1: 0.3762376237623763\n",
            "test performance:\n",
            "\t f1: 0.44976076555023925\n",
            "\t acc: 0.9499346974314323\n",
            "\t pre: 0.6714285714285714\n",
            "\t rec: 0.3381294964028777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQV-JMPfCfYk"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0hjoEZ6CiXq"
      },
      "source": [
        "In this notebook, we walked through the process of implementing LPA, GCN, GCNLPA and applied them to the problem space of detecting fraudulent bitcoin. \n",
        "The model implementation is relatively straight forward using PyTorch and PyTorch Geometric. (The hyperparamter optimization can be easily performed using optuna as well.) \n",
        "\n",
        "We find that GCNLPA leads to slightly better performance compared to GCN in all four aspects of classification, which are arruracy, F1 score, precision, and recall. GCNLPA and GCN both significantly outperform LPA. "
      ]
    }
  ]
}